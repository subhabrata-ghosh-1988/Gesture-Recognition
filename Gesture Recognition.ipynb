{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Gesture Recognition.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhabrata-ghosh-1988/Gesture-Recognition/blob/main/Gesture%20Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7ZfgtjxNVrR"
      },
      "source": [
        "# Gesture Recognition\n",
        "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-eH5pKuNVrV"
      },
      "source": [
        "## Import libraries\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy import misc\n",
        "from imageio import imread\n",
        "import cv2\n",
        "from skimage import transform,io\n",
        "import datetime\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import abc\n",
        "from sys import getsizeof\n",
        "import shutil\n",
        "import abc\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J94bqUhVNVrW"
      },
      "source": [
        "import glob, os , shutil\n",
        "for f in glob.glob(\"/content/model_init*\"):\n",
        "    shutil.rmtree(f)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Ubj-HfSRY3"
      },
      "source": [
        "## remove the existing zip file\r\n",
        "shutil.rmtree('/content/Project_data.zip', ignore_errors=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4ty5a19SiNl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "aa4219d1-2039-441c-b994-7409c5b181ab"
      },
      "source": [
        "## Initiate the file download\r\n",
        "!pip install gdown\r\n",
        "import gdown\r\n",
        "url=\"https://drive.google.com/uc?id=1kM4V7pnLjGbuCaDpfBNHig99gr2rdqyJ\"\r\n",
        "output = \"Project_data.zip\"\r\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kM4V7pnLjGbuCaDpfBNHig99gr2rdqyJ\n",
            "To: /content/Project_data.zip\n",
            "1.71GB [00:09, 180MB/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Project_data.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-fwe5jbTX8r"
      },
      "source": [
        "## unzip the downloaded folder\r\n",
        "shutil.rmtree('/content/Project_data', ignore_errors=True)\r\n",
        "shutil.unpack_archive(\"Project_data.zip\", \"Project_data\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIQHPGi_NVrX"
      },
      "source": [
        "We set the random seed so that the results don't vary drastically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci_N-NnWNVrZ"
      },
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bWyzW_oNVrZ"
      },
      "source": [
        "**In this block, you read the folder names for training and validation. You also set the batch_size here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyTupvi3NVrb"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCjeEg_tNVrc"
      },
      "source": [
        "# the entire dataset is placed in below directory\n",
        "main_folder='/content/Project_data/Project_data'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSUMkqaSXcC4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4e128d5d-3892-4fb0-fdf7-292c4d78f250"
      },
      "source": [
        "## Checking current TF version\r\n",
        "tf.version.VERSION"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REgxbVunNVrd"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3UJmY03NVre"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot(Model):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
        "    axes[0].plot(Model.history['loss'])   \n",
        "    axes[0].plot(Model.history['val_loss'])\n",
        "    axes[0].legend(['loss','val_loss'])\n",
        "\n",
        "    axes[1].plot(Model.history['categorical_accuracy'])   \n",
        "    axes[1].plot(Model.history['val_categorical_accuracy'])\n",
        "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtV6apQQNVrf"
      },
      "source": [
        "## Generator\n",
        "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haSnpGsboLKX"
      },
      "source": [
        "import gc\r\n",
        "class GCCallback(tf.keras.callbacks.Callback):\r\n",
        "      def on_epoch_end(self, epoch, logs=None):\r\n",
        "          print(gc.collect())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YC-BRedNVri"
      },
      "source": [
        "# referred ABC library use case from this link https://riptutorial.com/python/example/23083/why-how-to-use-abcmeta-and--abstractmethod\n",
        "\n",
        "class ModelBuilder(metaclass= abc.ABCMeta):\n",
        "    \n",
        "    def initialize_src_path(self,main_folder):\n",
        "        self.train_doc = np.random.permutation(open(main_folder + '/' + 'train.csv').readlines())\n",
        "        self.val_doc = np.random.permutation(open(main_folder + '/' + 'val.csv').readlines())\n",
        "        self.train_path = main_folder + '/' + 'train'\n",
        "        self.val_path =  main_folder + '/' + 'val'\n",
        "        self.num_train_sequences = len(self.train_doc)\n",
        "        self.num_val_sequences = len(self.val_doc)\n",
        "        \n",
        "    def initialize_image_properties(self,image_height=100,image_width=100):\n",
        "        self.image_height=image_height\n",
        "        self.image_width=image_width\n",
        "        self.channels=3\n",
        "        self.num_classes=5\n",
        "        self.total_frames=30\n",
        "          \n",
        "    def initialize_hyperparams(self,frames_to_sample=30,batch_size=40,num_epochs=20):\n",
        "        self.frames_to_sample=frames_to_sample\n",
        "        self.batch_size=batch_size\n",
        "        self.num_epochs=num_epochs\n",
        "        \n",
        "        \n",
        "    def generator(self,source_path, folder_list, augment=False):\n",
        "        img_idx = np.round(np.linspace(0,self.total_frames-1,self.frames_to_sample)).astype(int)\n",
        "        batch_size=self.batch_size\n",
        "        while True:\n",
        "            t = np.random.permutation(folder_list)\n",
        "            num_batches = len(t)//batch_size\n",
        "        \n",
        "            for batch in range(num_batches): \n",
        "                batch_data, batch_labels= self.one_batch_data(source_path,t,batch,batch_size,img_idx,augment)\n",
        "                yield batch_data, batch_labels \n",
        "\n",
        "            remaining_seq=len(t)%batch_size\n",
        "        \n",
        "            if (remaining_seq != 0):\n",
        "                batch_data, batch_labels= self.one_batch_data(source_path,t,num_batches,batch_size,img_idx,augment,remaining_seq)\n",
        "                yield batch_data, batch_labels \n",
        "    \n",
        "    \n",
        "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
        "    \n",
        "        seq_len = remaining_seq if remaining_seq else batch_size\n",
        "    \n",
        "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
        "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
        "    \n",
        "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
        "\n",
        "        \n",
        "        for folder in range(seq_len): \n",
        "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
        "            for idx,item in enumerate(img_idx): \n",
        "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                image_resized=transform.resize(image,(self.image_height,self.image_width,3))\n",
        "            \n",
        "\n",
        "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
        "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
        "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
        "            \n",
        "                if (augment):\n",
        "                    shifted = cv2.warpAffine(image, \n",
        "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
        "                                            (image.shape[1], image.shape[0]))\n",
        "                    \n",
        "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
        "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
        "                    \n",
        "                    cropped=shifted[x0:x1,y0:y1,:]\n",
        "                    \n",
        "                    image_resized=transform.resize(cropped,(self.image_height,self.image_width,3))\n",
        "            \n",
        "                    batch_data_aug[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
        "                    batch_data_aug[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
        "                    batch_data_aug[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
        "                \n",
        "            \n",
        "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            \n",
        "    \n",
        "        if (augment):\n",
        "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
        "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
        "\n",
        "        \n",
        "        return(batch_data,batch_labels)\n",
        "    \n",
        "    \n",
        "    def train_model(self, model, augment_data=False):\n",
        "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
        "        val_generator = self.generator(self.val_path, self.val_doc)\n",
        "\n",
        "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "        if not os.path.exists(model_name):\n",
        "            os.mkdir(model_name)\n",
        "        \n",
        "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
        "        callbacks_list = [checkpoint, LR, GCCallback()]\n",
        "\n",
        "        if (self.num_train_sequences%self.batch_size) == 0:\n",
        "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
        "        else:\n",
        "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
        "\n",
        "        if (self.num_val_sequences%self.batch_size) == 0:\n",
        "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
        "        else:\n",
        "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
        "    \n",
        "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
        "                            callbacks=callbacks_list, validation_data=val_generator, \n",
        "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
        "        return history\n",
        "\n",
        "    def clear_session(self, model):\n",
        "        del model\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "        tf.compat.v1.reset_default_graph() # TF graph isn't same as Keras graph\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def define_model(self):\n",
        "        pass\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkdCou-eNVri"
      },
      "source": [
        "## Sample Model\n",
        "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1XR94jpNVrk"
      },
      "source": [
        "class ModelConv3D1(ModelBuilder):\n",
        "    \n",
        "    def define_model(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Dense(64,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam()\n",
        "        #optimiser = 'sgd'\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIGA0cbNVrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0893a34a-0eb3-483d-f9be-54993832ffc6"
      },
      "source": [
        "Conv3D1=ModelConv3D1()\n",
        "Conv3D1.initialize_src_path(main_folder)\n",
        "Conv3D1.initialize_image_properties(image_height=160,image_width=160)\n",
        "Conv3D1.initialize_hyperparams(frames_to_sample=30,batch_size=30,num_epochs=1)\n",
        "Conv3D1_model=Conv3D1.define_model()\n",
        "Conv3D1_model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 30, 160, 160, 16)  1312      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 30, 160, 160, 16)  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 30, 160, 160, 16)  64        \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 15, 80, 80, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 15, 80, 80, 32)    4128      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 15, 80, 80, 32)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 15, 80, 80, 32)    128       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 7, 40, 40, 32)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 7, 40, 40, 64)     16448     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 7, 40, 40, 64)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 40, 40, 64)     256       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 3, 20, 20, 64)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 3, 20, 20, 128)    65664     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 3, 20, 20, 128)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 3, 20, 20, 128)    512       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 1, 10, 10, 128)    0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1638528   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 1,736,389\n",
            "Trainable params: 1,735,525\n",
            "Non-trainable params: 864\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eU6XuXdNVrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae4a73f-7539-4744-f71a-7f5651ee4b1d"
      },
      "source": [
        "Conv3D1.train_model(Conv3D1_model)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "23/23 [==============================] - ETA: 0s - batch: 11.0000 - size: 28.8261 - loss: 1.4350 - categorical_accuracy: 0.4646\n",
            "Epoch 00001: saving model to model_init_2021-03-1609_41_11.651024/model-00001-1.43496-0.46456-2.09574-0.18000.h5\n",
            "0\n",
            "23/23 [==============================] - 267s 11s/step - batch: 11.0000 - size: 28.8261 - loss: 1.4350 - categorical_accuracy: 0.4646 - val_loss: 2.0957 - val_categorical_accuracy: 0.1800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4fdf6ffd90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaJ-270dCcnY"
      },
      "source": [
        "Conv3D1.clear_session(Conv3D1_model)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPGUJrJXNVrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb551f0-f244-480f-9b53-97d691523823"
      },
      "source": [
        "Conv3D1_bs40=ModelConv3D1()\n",
        "Conv3D1_bs40.initialize_src_path(main_folder)\n",
        "Conv3D1_bs40.initialize_image_properties(image_height=160,image_width=160)\n",
        "Conv3D1_bs40.initialize_hyperparams(frames_to_sample=30,batch_size=40,num_epochs=1)\n",
        "Conv3D1_model_bs40=Conv3D1_bs40.define_model()\n",
        "Conv3D1_model_bs40.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 30, 160, 160, 16)  1312      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 30, 160, 160, 16)  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 30, 160, 160, 16)  64        \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 15, 80, 80, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 15, 80, 80, 32)    4128      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 15, 80, 80, 32)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 15, 80, 80, 32)    128       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 7, 40, 40, 32)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 7, 40, 40, 64)     16448     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 7, 40, 40, 64)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 40, 40, 64)     256       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 3, 20, 20, 64)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 3, 20, 20, 128)    65664     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 3, 20, 20, 128)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 3, 20, 20, 128)    512       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 1, 10, 10, 128)    0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1638528   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 1,736,389\n",
            "Trainable params: 1,735,525\n",
            "Non-trainable params: 864\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHCAyYjiNVro"
      },
      "source": [
        "#### Got below memory exhaust error with image resolution of 160x160, 30 frames and a batch_size of 40\n",
        "ResourceExhaustedError:  OOM when allocating tensor with shape[40,16,15,80,80] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
        "\t [[node gradient_tape/sequential_2/max_pooling3d_8/MaxPool3D/MaxPool3DGrad (defined at <ipython-input-11-c85facc09113>:122) ]]\n",
        "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
        " [Op:__inference_train_function_7489]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7SaHnFVNVro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3acc1646-de0b-45cc-da37-c7e5478a9cf1"
      },
      "source": [
        "print(\"Memory util is {} Gigs\". format(getsizeof(np.zeros((40,16,30,160,160)))/(1024*1024*1024)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory util is 3.662109524011612 Gigs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSsKCHtZNVrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d69440c-de41-4df7-b92f-1e8594e71634"
      },
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=30,num_epochs=3)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 1736389\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/3\n",
            "23/23 [==============================] - ETA: 0s - batch: 11.0000 - size: 28.8261 - loss: 1.5342 - categorical_accuracy: 0.4163\n",
            "Epoch 00001: saving model to model_init_2021-03-1609_45_47.279486/model-00001-1.53424-0.41629-2.80722-0.18000.h5\n",
            "4\n",
            "23/23 [==============================] - 157s 7s/step - batch: 11.0000 - size: 28.8261 - loss: 1.5342 - categorical_accuracy: 0.4163 - val_loss: 2.8072 - val_categorical_accuracy: 0.1800\n",
            "Epoch 2/3\n",
            "23/23 [==============================] - ETA: 0s - batch: 11.0000 - size: 28.8261 - loss: 1.0878 - categorical_accuracy: 0.5641\n",
            "Epoch 00002: saving model to model_init_2021-03-1609_45_47.279486/model-00002-1.08779-0.56410-3.85888-0.27000.h5\n",
            "0\n",
            "23/23 [==============================] - 123s 6s/step - batch: 11.0000 - size: 28.8261 - loss: 1.0878 - categorical_accuracy: 0.5641 - val_loss: 3.8589 - val_categorical_accuracy: 0.2700\n",
            "Epoch 3/3\n",
            "23/23 [==============================] - ETA: 0s - batch: 11.0000 - size: 28.8261 - loss: 0.8493 - categorical_accuracy: 0.6833\n",
            "Epoch 00003: saving model to model_init_2021-03-1609_45_47.279486/model-00003-0.84925-0.68326-4.80000-0.24000.h5\n",
            "0\n",
            "23/23 [==============================] - 125s 6s/step - batch: 11.0000 - size: 28.8261 - loss: 0.8493 - categorical_accuracy: 0.6833 - val_loss: 4.8000 - val_categorical_accuracy: 0.2400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4fa26ff310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx0kjX0PNVrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "189c7a9b-2017-4e32-cf51-7f60f92521af"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=30,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 687813\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - ETA: 0s - batch: 11.0000 - size: 28.8261 - loss: 1.6214 - categorical_accuracy: 0.3786\n",
            "Epoch 00001: saving model to model_init_2021-03-1609_52_34.811732/model-00001-1.62143-0.37858-2.15789-0.21000.h5\n",
            "48\n",
            "23/23 [==============================] - 235s 10s/step - batch: 11.0000 - size: 28.8261 - loss: 1.6214 - categorical_accuracy: 0.3786 - val_loss: 2.1579 - val_categorical_accuracy: 0.2100\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - ETA: 0s - batch: 11.0000 - size: 28.8261 - loss: 1.1431 - categorical_accuracy: 0.5732\n",
            "Epoch 00002: saving model to model_init_2021-03-1609_52_34.811732/model-00002-1.14314-0.57315-4.19798-0.16000.h5\n",
            "0\n",
            "23/23 [==============================] - 197s 9s/step - batch: 11.0000 - size: 28.8261 - loss: 1.1431 - categorical_accuracy: 0.5732 - val_loss: 4.1980 - val_categorical_accuracy: 0.1600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4fa216ebd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xReB_wtlNVrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaca1524-d2ae-4fc9-cc34-ef4e1d6acea1"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=60,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 687813\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "12/12 [==============================] - ETA: 0s - batch: 5.5000 - size: 55.2500 - loss: 1.6533 - categorical_accuracy: 0.3906 \n",
            "Epoch 00001: saving model to model_init_2021-03-1609_59_48.849128/model-00001-1.65330-0.39065-1.84520-0.16000.h5\n",
            "48\n",
            "12/12 [==============================] - 234s 19s/step - batch: 5.5000 - size: 55.2500 - loss: 1.6533 - categorical_accuracy: 0.3906 - val_loss: 1.8452 - val_categorical_accuracy: 0.1600\n",
            "Epoch 2/2\n",
            "12/12 [==============================] - ETA: 0s - batch: 5.5000 - size: 55.2500 - loss: 1.1881 - categorical_accuracy: 0.5520 \n",
            "Epoch 00002: saving model to model_init_2021-03-1609_59_48.849128/model-00002-1.18807-0.55204-3.28415-0.16000.h5\n",
            "0\n",
            "12/12 [==============================] - 209s 19s/step - batch: 5.5000 - size: 55.2500 - loss: 1.1881 - categorical_accuracy: 0.5520 - val_loss: 3.2842 - val_categorical_accuracy: 0.1600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4fa04818d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoKopL3YNVry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e926ad94-f5bb-440f-a4f5-f971641c7de6"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=60,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 687813\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "12/12 [==============================] - ETA: 0s - batch: 5.5000 - size: 55.2500 - loss: 1.6485 - categorical_accuracy: 0.3680\n",
            "Epoch 00001: saving model to model_init_2021-03-1610_07_15.236343/model-00001-1.64850-0.36802-1.66884-0.24000.h5\n",
            "48\n",
            "12/12 [==============================] - 130s 10s/step - batch: 5.5000 - size: 55.2500 - loss: 1.6485 - categorical_accuracy: 0.3680 - val_loss: 1.6688 - val_categorical_accuracy: 0.2400\n",
            "Epoch 2/2\n",
            "11/12 [==========================>...] - ETA: 8s - batch: 5.0000 - size: 60.0000 - loss: 1.1689 - categorical_accuracy: 0.5530 \n",
            "Epoch 00002: saving model to model_init_2021-03-1610_07_15.236343/model-00002-1.19169-0.55204-1.85457-0.22000.h5\n",
            "0\n",
            "12/12 [==============================] - 109s 10s/step - batch: 5.5000 - size: 55.2500 - loss: 1.1917 - categorical_accuracy: 0.5520 - val_loss: 1.8546 - val_categorical_accuracy: 0.2200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f54b00d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHABNT4GNVry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "747ce63c-79ba-499f-ca32-5b5be6717571"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=80,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 687813\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "9/9 [==============================] - ETA: 0s - batch: 4.0000 - size: 73.6667 - loss: 1.7151 - categorical_accuracy: 0.3725 \n",
            "Epoch 00001: saving model to model_init_2021-03-1610_11_16.996681/model-00001-1.71507-0.37255-1.64277-0.24000.h5\n",
            "48\n",
            "9/9 [==============================] - 134s 14s/step - batch: 4.0000 - size: 73.6667 - loss: 1.7151 - categorical_accuracy: 0.3725 - val_loss: 1.6428 - val_categorical_accuracy: 0.2400\n",
            "Epoch 2/2\n",
            "9/9 [==============================] - ETA: 0s - batch: 4.0000 - size: 73.6667 - loss: 1.1304 - categorical_accuracy: 0.5807 \n",
            "Epoch 00002: saving model to model_init_2021-03-1610_11_16.996681/model-00002-1.13041-0.58069-2.41928-0.16000.h5\n",
            "0\n",
            "9/9 [==============================] - 109s 14s/step - batch: 4.0000 - size: 73.6667 - loss: 1.1304 - categorical_accuracy: 0.5807 - val_loss: 2.4193 - val_categorical_accuracy: 0.1600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f56ddcd90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2T9W4HyNVrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4516796c-2fd3-440b-ca73-074c4ab778d8"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=15,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 1736389\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "45/45 [==============================] - ETA: 0s - batch: 22.0000 - size: 14.7333 - loss: 1.5826 - categorical_accuracy: 0.4329\n",
            "Epoch 00001: saving model to model_init_2021-03-1610_15_22.605423/model-00001-1.58257-0.43288-2.77167-0.24000.h5\n",
            "48\n",
            "45/45 [==============================] - 270s 6s/step - batch: 22.0000 - size: 14.7333 - loss: 1.5826 - categorical_accuracy: 0.4329 - val_loss: 2.7717 - val_categorical_accuracy: 0.2400\n",
            "Epoch 2/2\n",
            "45/45 [==============================] - ETA: 0s - batch: 22.0000 - size: 14.7333 - loss: 1.0508 - categorical_accuracy: 0.5882\n",
            "Epoch 00002: saving model to model_init_2021-03-1610_15_22.605423/model-00002-1.05078-0.58824-6.31989-0.17000.h5\n",
            "0\n",
            "45/45 [==============================] - 230s 5s/step - batch: 22.0000 - size: 14.7333 - loss: 1.0508 - categorical_accuracy: 0.5882 - val_loss: 6.3199 - val_categorical_accuracy: 0.1700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f57333cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25WU3xHcNVrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43fac2c5-a60e-42fc-f845-a38fa0855e8d"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=15,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 1736389\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "45/45 [==============================] - ETA: 0s - batch: 22.0000 - size: 14.7333 - loss: 1.6042 - categorical_accuracy: 0.4314\n",
            "Epoch 00001: saving model to model_init_2021-03-1610_23_44.926336/model-00001-1.60423-0.43137-5.21009-0.21000.h5\n",
            "48\n",
            "45/45 [==============================] - 146s 3s/step - batch: 22.0000 - size: 14.7333 - loss: 1.6042 - categorical_accuracy: 0.4314 - val_loss: 5.2101 - val_categorical_accuracy: 0.2100\n",
            "Epoch 2/2\n",
            "45/45 [==============================] - ETA: 0s - batch: 22.0000 - size: 14.7333 - loss: 1.0936 - categorical_accuracy: 0.5747\n",
            "Epoch 00002: saving model to model_init_2021-03-1610_23_44.926336/model-00002-1.09355-0.57466-6.48449-0.21000.h5\n",
            "0\n",
            "45/45 [==============================] - 122s 3s/step - batch: 22.0000 - size: 14.7333 - loss: 1.0936 - categorical_accuracy: 0.5747 - val_loss: 6.4845 - val_categorical_accuracy: 0.2100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f57b2f110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPzFJDfUNVr0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b10fa7f-dc4b-434a-9d34-0257218161fe"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=15,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 687813\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "45/45 [==============================] - ETA: 0s - batch: 22.0000 - size: 14.7333 - loss: 1.7345 - categorical_accuracy: 0.3484\n",
            "Epoch 00001: saving model to model_init_2021-03-1610_28_15.853693/model-00001-1.73454-0.34842-2.44110-0.21000.h5\n",
            "48\n",
            "45/45 [==============================] - 127s 3s/step - batch: 22.0000 - size: 14.7333 - loss: 1.7345 - categorical_accuracy: 0.3484 - val_loss: 2.4411 - val_categorical_accuracy: 0.2100\n",
            "Epoch 2/2\n",
            "45/45 [==============================] - ETA: 0s - batch: 22.0000 - size: 14.7333 - loss: 1.2101 - categorical_accuracy: 0.5324\n",
            "Epoch 00002: saving model to model_init_2021-03-1610_28_15.853693/model-00002-1.21005-0.53243-2.75558-0.23000.h5\n",
            "0\n",
            "45/45 [==============================] - 107s 2s/step - batch: 22.0000 - size: 14.7333 - loss: 1.2101 - categorical_accuracy: 0.5324 - val_loss: 2.7556 - val_categorical_accuracy: 0.2300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f575a6e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdQ6Aed-NVr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dae2a36-e7c4-41c6-8008-0559e0c8d0a6"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=10,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 687813\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.6351 - categorical_accuracy: 0.3861 \n",
            "Epoch 00001: saving model to model_init_2021-03-1610_32_12.275621/model-00001-1.63514-0.38612-5.49332-0.16000.h5\n",
            "48\n",
            "67/67 [==============================] - 125s 2s/step - batch: 33.0000 - size: 9.8955 - loss: 1.6351 - categorical_accuracy: 0.3861 - val_loss: 5.4933 - val_categorical_accuracy: 0.1600\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.2190 - categorical_accuracy: 0.5219 \n",
            "Epoch 00002: saving model to model_init_2021-03-1610_32_12.275621/model-00002-1.21904-0.52187-7.80837-0.16000.h5\n",
            "0\n",
            "67/67 [==============================] - 106s 2s/step - batch: 33.0000 - size: 9.8955 - loss: 1.2190 - categorical_accuracy: 0.5219 - val_loss: 7.8084 - val_categorical_accuracy: 0.1600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f569fe710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OYsvNb7NVr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1110512e-8518-41ad-fe55-c32d0c68ab61"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=10,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 687813\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.6592 - categorical_accuracy: 0.3650 \n",
            "Epoch 00001: saving model to model_init_2021-03-1610_36_04.606069/model-00001-1.65924-0.36501-4.66347-0.16000.h5\n",
            "48\n",
            "67/67 [==============================] - 226s 3s/step - batch: 33.0000 - size: 9.8955 - loss: 1.6592 - categorical_accuracy: 0.3650 - val_loss: 4.6635 - val_categorical_accuracy: 0.1600\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.2444 - categorical_accuracy: 0.5068 \n",
            "Epoch 00002: saving model to model_init_2021-03-1610_36_04.606069/model-00002-1.24444-0.50679-9.06098-0.17000.h5\n",
            "0\n",
            "67/67 [==============================] - 208s 3s/step - batch: 33.0000 - size: 9.8955 - loss: 1.2444 - categorical_accuracy: 0.5068 - val_loss: 9.0610 - val_categorical_accuracy: 0.1700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4fa1ee9850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D4BJx6gNVr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8dd42d-e5a3-4023-d686-16cee0d4f611"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=10,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 1736389\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.5864 - categorical_accuracy: 0.4389 \n",
            "Epoch 00001: saving model to model_init_2021-03-1610_43_20.193678/model-00001-1.58642-0.43891-7.43368-0.16000.h5\n",
            "48\n",
            "67/67 [==============================] - 265s 4s/step - batch: 33.0000 - size: 9.8955 - loss: 1.5864 - categorical_accuracy: 0.4389 - val_loss: 7.4337 - val_categorical_accuracy: 0.1600\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.2252 - categorical_accuracy: 0.5475 \n",
            "Epoch 00002: saving model to model_init_2021-03-1610_43_20.193678/model-00002-1.22516-0.54751-7.87354-0.31000.h5\n",
            "0\n",
            "67/67 [==============================] - 228s 3s/step - batch: 33.0000 - size: 9.8955 - loss: 1.2252 - categorical_accuracy: 0.5475 - val_loss: 7.8735 - val_categorical_accuracy: 0.3100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4fa19bec90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo38TA_HNVr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab293f6c-0726-4c72-e321-90be0f8e5e87"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=10,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 1736389\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.6417 - categorical_accuracy: 0.4103 \n",
            "Epoch 00001: saving model to model_init_2021-03-1610_51_34.371538/model-00001-1.64168-0.41026-10.58059-0.21000.h5\n",
            "48\n",
            "67/67 [==============================] - 145s 2s/step - batch: 33.0000 - size: 9.8955 - loss: 1.6417 - categorical_accuracy: 0.4103 - val_loss: 10.5806 - val_categorical_accuracy: 0.2100\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.3090 - categorical_accuracy: 0.4796 \n",
            "Epoch 00002: saving model to model_init_2021-03-1610_51_34.371538/model-00002-1.30897-0.47964-10.01504-0.23000.h5\n",
            "0\n",
            "67/67 [==============================] - 124s 2s/step - batch: 33.0000 - size: 9.8955 - loss: 1.3090 - categorical_accuracy: 0.4796 - val_loss: 10.0150 - val_categorical_accuracy: 0.2300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f5d0b4350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns4lmR9bNVr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8869bc71-84a2-4dd7-d348-2f079f56d082"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=40,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 1736389\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 1.5491 - categorical_accuracy: 0.4434\n",
            "Epoch 00001: saving model to model_init_2021-03-1610_56_05.542566/model-00001-1.54910-0.44344-1.92613-0.21000.h5\n",
            "48\n",
            "17/17 [==============================] - 144s 8s/step - batch: 8.0000 - size: 39.0000 - loss: 1.5491 - categorical_accuracy: 0.4434 - val_loss: 1.9261 - val_categorical_accuracy: 0.2100\n",
            "Epoch 2/2\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.9681 - categorical_accuracy: 0.6425\n",
            "Epoch 00002: saving model to model_init_2021-03-1610_56_05.542566/model-00002-0.96810-0.64253-4.35986-0.18000.h5\n",
            "0\n",
            "17/17 [==============================] - 125s 8s/step - batch: 8.0000 - size: 39.0000 - loss: 0.9681 - categorical_accuracy: 0.6425 - val_loss: 4.3599 - val_categorical_accuracy: 0.1800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f5cb8cdd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVh5rIRCNVr7"
      },
      "source": [
        "### Observation\n",
        "\n",
        "**As we see from the above experiments image resolution and number of frames in sequence have more impact on training time than batch_size.**\n",
        "\n",
        "So experimentations are carried with batch size fixed around 15-40 and changing the resolution and number of image per sequence based on the device memory constraints . Models are designed such that their memory foot print is less than 50 MB which corresponds to 4.3 million parameters assuming the datatype size of parameters to be 12 bytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKbxe-Szy15j"
      },
      "source": [
        "## Model 1 - Base Model - No Data Augmentation Batch Size 40 and Epoch 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LVQM4NsNVr7"
      },
      "source": [
        "class ModelConv3D1(ModelBuilder):\r\n",
        "    \r\n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\r\n",
        "\r\n",
        "        model = Sequential()\r\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\r\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Flatten())\r\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(dropout))\r\n",
        "\r\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(dropout))\r\n",
        "\r\n",
        "\r\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\r\n",
        "\r\n",
        "        optimiser = optimizers.Adam()\r\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\r\n",
        "        return model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-89dV5W8WAw3",
        "outputId": "afc3362a-f256-4560-d2ae-6759b3f8c856"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\r\n",
        "Conv3D1=ModelConv3D1()\r\n",
        "Conv3D1.initialize_src_path(main_folder)\r\n",
        "Conv3D1.initialize_image_properties(image_height=160,image_width=160)\r\n",
        "Conv3D1.initialize_hyperparams(frames_to_sample=20,batch_size=40,num_epochs=15)\r\n",
        "Conv3D1_model=Conv3D1.define_model()\r\n",
        "Conv3D1_model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 20, 160, 160, 16)  1312      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 20, 160, 160, 16)  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 20, 160, 160, 16)  64        \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 10, 80, 80, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 10, 80, 80, 32)    13856     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10, 80, 80, 32)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 10, 80, 80, 32)    128       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 5, 40, 40, 32)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 5, 40, 40, 64)     55360     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 5, 40, 40, 64)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 5, 40, 40, 64)     256       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 2, 20, 20, 64)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 2, 20, 20, 128)    221312    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2, 20, 20, 128)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 20, 20, 128)    512       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 1, 10, 10, 128)    0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                819264    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 1,117,061\n",
            "Trainable params: 1,116,325\n",
            "Non-trainable params: 736\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j884vjoWQD0",
        "outputId": "d65930b7-a725-4c8b-e2ec-523859521729"
      },
      "source": [
        "print(\"Total Params:\", Conv3D1_model.count_params())\r\n",
        "accuracy_check_model_1 = Conv3D1.train_model(Conv3D1_model)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 1117061\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 1.4599 - categorical_accuracy: 0.4359\n",
            "Epoch 00001: saving model to model_init_2021-03-1611_00_37.773482/model-00001-1.45995-0.43590-2.27087-0.21000.h5\n",
            "48\n",
            "17/17 [==============================] - 183s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 1.4599 - categorical_accuracy: 0.4359 - val_loss: 2.2709 - val_categorical_accuracy: 0.2100\n",
            "Epoch 2/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.9652 - categorical_accuracy: 0.6244\n",
            "Epoch 00002: saving model to model_init_2021-03-1611_00_37.773482/model-00002-0.96520-0.62443-3.57726-0.23000.h5\n",
            "0\n",
            "17/17 [==============================] - 157s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 0.9652 - categorical_accuracy: 0.6244 - val_loss: 3.5773 - val_categorical_accuracy: 0.2300\n",
            "Epoch 3/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.7494 - categorical_accuracy: 0.7255\n",
            "Epoch 00003: saving model to model_init_2021-03-1611_00_37.773482/model-00003-0.74938-0.72549-4.74245-0.22000.h5\n",
            "0\n",
            "17/17 [==============================] - 154s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 0.7494 - categorical_accuracy: 0.7255 - val_loss: 4.7424 - val_categorical_accuracy: 0.2200\n",
            "Epoch 4/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.6639 - categorical_accuracy: 0.7526\n",
            "Epoch 00004: saving model to model_init_2021-03-1611_00_37.773482/model-00004-0.66387-0.75264-3.39949-0.21000.h5\n",
            "0\n",
            "17/17 [==============================] - 154s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 0.6639 - categorical_accuracy: 0.7526 - val_loss: 3.3995 - val_categorical_accuracy: 0.2100\n",
            "Epoch 5/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.4698 - categorical_accuracy: 0.8265\n",
            "Epoch 00005: saving model to model_init_2021-03-1611_00_37.773482/model-00005-0.46979-0.82655-4.89329-0.17000.h5\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "0\n",
            "17/17 [==============================] - 155s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 0.4698 - categorical_accuracy: 0.8265 - val_loss: 4.8933 - val_categorical_accuracy: 0.1700\n",
            "Epoch 6/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.4118 - categorical_accuracy: 0.8446\n",
            "Epoch 00006: saving model to model_init_2021-03-1611_00_37.773482/model-00006-0.41182-0.84465-4.39975-0.25000.h5\n",
            "0\n",
            "17/17 [==============================] - 158s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 0.4118 - categorical_accuracy: 0.8446 - val_loss: 4.3997 - val_categorical_accuracy: 0.2500\n",
            "Epoch 7/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.2987 - categorical_accuracy: 0.9050\n",
            "Epoch 00007: saving model to model_init_2021-03-1611_00_37.773482/model-00007-0.29869-0.90498-5.04272-0.21000.h5\n",
            "0\n",
            "17/17 [==============================] - 154s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 0.2987 - categorical_accuracy: 0.9050 - val_loss: 5.0427 - val_categorical_accuracy: 0.2100\n",
            "Epoch 8/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.2850 - categorical_accuracy: 0.9155\n",
            "Epoch 00008: saving model to model_init_2021-03-1611_00_37.773482/model-00008-0.28500-0.91554-5.65427-0.21000.h5\n",
            "0\n",
            "17/17 [==============================] - 155s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 0.2850 - categorical_accuracy: 0.9155 - val_loss: 5.6543 - val_categorical_accuracy: 0.2100\n",
            "Epoch 9/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.2554 - categorical_accuracy: 0.9336\n",
            "Epoch 00009: saving model to model_init_2021-03-1611_00_37.773482/model-00009-0.25535-0.93363-5.95702-0.21000.h5\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "0\n",
            "17/17 [==============================] - 157s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 0.2554 - categorical_accuracy: 0.9336 - val_loss: 5.9570 - val_categorical_accuracy: 0.2100\n",
            "Epoch 10/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.2278 - categorical_accuracy: 0.9351\n",
            "Epoch 00010: saving model to model_init_2021-03-1611_00_37.773482/model-00010-0.22785-0.93514-6.36046-0.21000.h5\n",
            "0\n",
            "17/17 [==============================] - 153s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 0.2278 - categorical_accuracy: 0.9351 - val_loss: 6.3605 - val_categorical_accuracy: 0.2100\n",
            "Epoch 11/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.2124 - categorical_accuracy: 0.9517\n",
            "Epoch 00011: saving model to model_init_2021-03-1611_00_37.773482/model-00011-0.21244-0.95173-6.61758-0.19000.h5\n",
            "0\n",
            "17/17 [==============================] - 157s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 0.2124 - categorical_accuracy: 0.9517 - val_loss: 6.6176 - val_categorical_accuracy: 0.1900\n",
            "Epoch 12/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.2143 - categorical_accuracy: 0.9457\n",
            "Epoch 00012: saving model to model_init_2021-03-1611_00_37.773482/model-00012-0.21432-0.94570-6.37276-0.24000.h5\n",
            "0\n",
            "17/17 [==============================] - 159s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 0.2143 - categorical_accuracy: 0.9457 - val_loss: 6.3728 - val_categorical_accuracy: 0.2400\n",
            "Epoch 13/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.2184 - categorical_accuracy: 0.9472\n",
            "Epoch 00013: saving model to model_init_2021-03-1611_00_37.773482/model-00013-0.21837-0.94721-6.53760-0.21000.h5\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "0\n",
            "17/17 [==============================] - 153s 9s/step - batch: 8.0000 - size: 39.0000 - loss: 0.2184 - categorical_accuracy: 0.9472 - val_loss: 6.5376 - val_categorical_accuracy: 0.2100\n",
            "Epoch 14/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.1967 - categorical_accuracy: 0.9412\n",
            "Epoch 00014: saving model to model_init_2021-03-1611_00_37.773482/model-00014-0.19666-0.94118-6.68050-0.23000.h5\n",
            "0\n",
            "17/17 [==============================] - 157s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 0.1967 - categorical_accuracy: 0.9412 - val_loss: 6.6805 - val_categorical_accuracy: 0.2300\n",
            "Epoch 15/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.1925 - categorical_accuracy: 0.9548\n",
            "Epoch 00015: saving model to model_init_2021-03-1611_00_37.773482/model-00015-0.19254-0.95475-6.63226-0.19000.h5\n",
            "0\n",
            "17/17 [==============================] - 155s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 0.1925 - categorical_accuracy: 0.9548 - val_loss: 6.6323 - val_categorical_accuracy: 0.1900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "r00TPGbNXXhX",
        "outputId": "7a7b9ac5-d2d6-4f12-a0ad-b2966924c0f5"
      },
      "source": [
        "plot(accuracy_check_model_1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtxwayy_14Hn"
      },
      "source": [
        "#### Model is clearly overfitting. So we need to do data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJk2twS_2lRx"
      },
      "source": [
        "## Model 2 - Augment Data , (3,3,3) filter & 160x160 image resolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQxHzlc92oOq",
        "outputId": "894b6282-1f55-4f89-c750-0859dbe10c9f"
      },
      "source": [
        "Conv3D1.clear_session(Conv3D1_model)\r\n",
        "Conv3D2=ModelConv3D1()\r\n",
        "Conv3D2.initialize_src_path(main_folder)\r\n",
        "Conv3D2.initialize_image_properties(image_height=160,image_width=160)\r\n",
        "Conv3D2.initialize_hyperparams(frames_to_sample=20,batch_size=20,num_epochs=25)\r\n",
        "Conv3D2_model=Conv3D2.define_model(dense_neurons=256,dropout=0.5)\r\n",
        "Conv3D2_model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 20, 160, 160, 16)  1312      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 20, 160, 160, 16)  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 20, 160, 160, 16)  64        \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 10, 80, 80, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 10, 80, 80, 32)    13856     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10, 80, 80, 32)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 10, 80, 80, 32)    128       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 5, 40, 40, 32)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 5, 40, 40, 64)     55360     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 5, 40, 40, 64)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 5, 40, 40, 64)     256       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 2, 20, 20, 64)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 2, 20, 20, 128)    221312    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2, 20, 20, 128)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 20, 20, 128)    512       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 1, 10, 10, 128)    0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               3277056   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 3,638,981\n",
            "Trainable params: 3,637,477\n",
            "Non-trainable params: 1,504\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCx8waqu3PY9",
        "outputId": "bb8271b9-5c91-4712-faa0-e1e0e65f4b21"
      },
      "source": [
        "print(\"Total Params:\", Conv3D2_model.count_params())\r\n",
        "accuracy_check_model_2=Conv3D2.train_model(Conv3D2_model,augment_data=True)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 3638981\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 1.8178 - categorical_accuracy: 0.3997\n",
            "Epoch 00001: saving model to model_init_2021-03-1611_48_10.230425/model-00001-1.81782-0.39970-2.66929-0.25000.h5\n",
            "48\n",
            "34/34 [==============================] - 313s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 1.8178 - categorical_accuracy: 0.3997 - val_loss: 2.6693 - val_categorical_accuracy: 0.2500\n",
            "Epoch 2/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 1.3409 - categorical_accuracy: 0.5347\n",
            "Epoch 00002: saving model to model_init_2021-03-1611_48_10.230425/model-00002-1.34087-0.53469-7.12469-0.19000.h5\n",
            "0\n",
            "34/34 [==============================] - 284s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 1.3409 - categorical_accuracy: 0.5347 - val_loss: 7.1247 - val_categorical_accuracy: 0.1900\n",
            "Epoch 3/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 1.2948 - categorical_accuracy: 0.5626\n",
            "Epoch 00003: saving model to model_init_2021-03-1611_48_10.230425/model-00003-1.29481-0.56259-6.83948-0.23000.h5\n",
            "0\n",
            "34/34 [==============================] - 281s 8s/step - batch: 16.5000 - size: 39.0000 - loss: 1.2948 - categorical_accuracy: 0.5626 - val_loss: 6.8395 - val_categorical_accuracy: 0.2300\n",
            "Epoch 4/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 1.1348 - categorical_accuracy: 0.6116\n",
            "Epoch 00004: saving model to model_init_2021-03-1611_48_10.230425/model-00004-1.13481-0.61161-9.42922-0.20000.h5\n",
            "0\n",
            "34/34 [==============================] - 287s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 1.1348 - categorical_accuracy: 0.6116 - val_loss: 9.4292 - val_categorical_accuracy: 0.2000\n",
            "Epoch 5/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 1.0374 - categorical_accuracy: 0.6320\n",
            "Epoch 00005: saving model to model_init_2021-03-1611_48_10.230425/model-00005-1.03736-0.63198-8.53804-0.23000.h5\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "0\n",
            "34/34 [==============================] - 281s 8s/step - batch: 16.5000 - size: 39.0000 - loss: 1.0374 - categorical_accuracy: 0.6320 - val_loss: 8.5380 - val_categorical_accuracy: 0.2300\n",
            "Epoch 6/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.7869 - categorical_accuracy: 0.6983\n",
            "Epoch 00006: saving model to model_init_2021-03-1611_48_10.230425/model-00006-0.78693-0.69834-8.21821-0.21000.h5\n",
            "0\n",
            "34/34 [==============================] - 282s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.7869 - categorical_accuracy: 0.6983 - val_loss: 8.2182 - val_categorical_accuracy: 0.2100\n",
            "Epoch 7/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.7576 - categorical_accuracy: 0.7195\n",
            "Epoch 00007: saving model to model_init_2021-03-1611_48_10.230425/model-00007-0.75762-0.71946-7.19118-0.20000.h5\n",
            "0\n",
            "34/34 [==============================] - 284s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.7576 - categorical_accuracy: 0.7195 - val_loss: 7.1912 - val_categorical_accuracy: 0.2000\n",
            "Epoch 8/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.7131 - categorical_accuracy: 0.7376\n",
            "Epoch 00008: saving model to model_init_2021-03-1611_48_10.230425/model-00008-0.71307-0.73756-6.38430-0.20000.h5\n",
            "0\n",
            "34/34 [==============================] - 285s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.7131 - categorical_accuracy: 0.7376 - val_loss: 6.3843 - val_categorical_accuracy: 0.2000\n",
            "Epoch 9/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6209 - categorical_accuracy: 0.7738\n",
            "Epoch 00009: saving model to model_init_2021-03-1611_48_10.230425/model-00009-0.62089-0.77376-5.59594-0.27000.h5\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "0\n",
            "34/34 [==============================] - 289s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6209 - categorical_accuracy: 0.7738 - val_loss: 5.5959 - val_categorical_accuracy: 0.2700\n",
            "Epoch 10/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6263 - categorical_accuracy: 0.7722\n",
            "Epoch 00010: saving model to model_init_2021-03-1611_48_10.230425/model-00010-0.62634-0.77225-5.03875-0.25000.h5\n",
            "0\n",
            "34/34 [==============================] - 285s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6263 - categorical_accuracy: 0.7722 - val_loss: 5.0388 - val_categorical_accuracy: 0.2500\n",
            "Epoch 11/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6039 - categorical_accuracy: 0.7730\n",
            "Epoch 00011: saving model to model_init_2021-03-1611_48_10.230425/model-00011-0.60394-0.77300-4.52237-0.23000.h5\n",
            "0\n",
            "34/34 [==============================] - 290s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6039 - categorical_accuracy: 0.7730 - val_loss: 4.5224 - val_categorical_accuracy: 0.2300\n",
            "Epoch 12/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6108 - categorical_accuracy: 0.7798\n",
            "Epoch 00012: saving model to model_init_2021-03-1611_48_10.230425/model-00012-0.61080-0.77979-3.43379-0.27000.h5\n",
            "0\n",
            "34/34 [==============================] - 286s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6108 - categorical_accuracy: 0.7798 - val_loss: 3.4338 - val_categorical_accuracy: 0.2700\n",
            "Epoch 13/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.5515 - categorical_accuracy: 0.7956\n",
            "Epoch 00013: saving model to model_init_2021-03-1611_48_10.230425/model-00013-0.55149-0.79563-3.14635-0.22000.h5\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "0\n",
            "34/34 [==============================] - 291s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.5515 - categorical_accuracy: 0.7956 - val_loss: 3.1464 - val_categorical_accuracy: 0.2200\n",
            "Epoch 14/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6120 - categorical_accuracy: 0.7843\n",
            "Epoch 00014: saving model to model_init_2021-03-1611_48_10.230425/model-00014-0.61197-0.78431-2.45230-0.33000.h5\n",
            "0\n",
            "34/34 [==============================] - 286s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6120 - categorical_accuracy: 0.7843 - val_loss: 2.4523 - val_categorical_accuracy: 0.3300\n",
            "Epoch 15/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.5553 - categorical_accuracy: 0.7866\n",
            "Epoch 00015: saving model to model_init_2021-03-1611_48_10.230425/model-00015-0.55535-0.78658-2.21543-0.38000.h5\n",
            "0\n",
            "34/34 [==============================] - 289s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.5553 - categorical_accuracy: 0.7866 - val_loss: 2.2154 - val_categorical_accuracy: 0.3800\n",
            "Epoch 16/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.5156 - categorical_accuracy: 0.8122\n",
            "Epoch 00016: saving model to model_init_2021-03-1611_48_10.230425/model-00016-0.51565-0.81222-1.66385-0.45000.h5\n",
            "0\n",
            "34/34 [==============================] - 285s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.5156 - categorical_accuracy: 0.8122 - val_loss: 1.6638 - val_categorical_accuracy: 0.4500\n",
            "Epoch 17/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.5787 - categorical_accuracy: 0.7934\n",
            "Epoch 00017: saving model to model_init_2021-03-1611_48_10.230425/model-00017-0.57868-0.79336-1.20998-0.55000.h5\n",
            "0\n",
            "34/34 [==============================] - 285s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.5787 - categorical_accuracy: 0.7934 - val_loss: 1.2100 - val_categorical_accuracy: 0.5500\n",
            "Epoch 18/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.5621 - categorical_accuracy: 0.7934\n",
            "Epoch 00018: saving model to model_init_2021-03-1611_48_10.230425/model-00018-0.56210-0.79336-1.07097-0.62000.h5\n",
            "0\n",
            "34/34 [==============================] - 285s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.5621 - categorical_accuracy: 0.7934 - val_loss: 1.0710 - val_categorical_accuracy: 0.6200\n",
            "Epoch 19/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.5744 - categorical_accuracy: 0.7956\n",
            "Epoch 00019: saving model to model_init_2021-03-1611_48_10.230425/model-00019-0.57436-0.79563-0.93357-0.68000.h5\n",
            "0\n",
            "34/34 [==============================] - 284s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.5744 - categorical_accuracy: 0.7956 - val_loss: 0.9336 - val_categorical_accuracy: 0.6800\n",
            "Epoch 20/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6404 - categorical_accuracy: 0.7624\n",
            "Epoch 00020: saving model to model_init_2021-03-1611_48_10.230425/model-00020-0.64039-0.76244-0.84762-0.72000.h5\n",
            "0\n",
            "34/34 [==============================] - 283s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6404 - categorical_accuracy: 0.7624 - val_loss: 0.8476 - val_categorical_accuracy: 0.7200\n",
            "Epoch 21/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.5131 - categorical_accuracy: 0.7956\n",
            "Epoch 00021: saving model to model_init_2021-03-1611_48_10.230425/model-00021-0.51308-0.79563-0.77741-0.71000.h5\n",
            "0\n",
            "34/34 [==============================] - 287s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.5131 - categorical_accuracy: 0.7956 - val_loss: 0.7774 - val_categorical_accuracy: 0.7100\n",
            "Epoch 22/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.4992 - categorical_accuracy: 0.8062\n",
            "Epoch 00022: saving model to model_init_2021-03-1611_48_10.230425/model-00022-0.49922-0.80618-0.62357-0.76000.h5\n",
            "0\n",
            "34/34 [==============================] - 284s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.4992 - categorical_accuracy: 0.8062 - val_loss: 0.6236 - val_categorical_accuracy: 0.7600\n",
            "Epoch 23/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.5030 - categorical_accuracy: 0.8054\n",
            "Epoch 00023: saving model to model_init_2021-03-1611_48_10.230425/model-00023-0.50301-0.80543-0.73684-0.71000.h5\n",
            "0\n",
            "34/34 [==============================] - 281s 8s/step - batch: 16.5000 - size: 39.0000 - loss: 0.5030 - categorical_accuracy: 0.8054 - val_loss: 0.7368 - val_categorical_accuracy: 0.7100\n",
            "Epoch 24/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.5774 - categorical_accuracy: 0.7971\n",
            "Epoch 00024: saving model to model_init_2021-03-1611_48_10.230425/model-00024-0.57740-0.79713-0.58314-0.78000.h5\n",
            "0\n",
            "34/34 [==============================] - 285s 9s/step - batch: 16.5000 - size: 39.0000 - loss: 0.5774 - categorical_accuracy: 0.7971 - val_loss: 0.5831 - val_categorical_accuracy: 0.7800\n",
            "Epoch 25/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.5382 - categorical_accuracy: 0.7941\n",
            "Epoch 00025: saving model to model_init_2021-03-1611_48_10.230425/model-00025-0.53820-0.79412-0.57240-0.80000.h5\n",
            "0\n",
            "34/34 [==============================] - 282s 8s/step - batch: 16.5000 - size: 39.0000 - loss: 0.5382 - categorical_accuracy: 0.7941 - val_loss: 0.5724 - val_categorical_accuracy: 0.8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "PXZ8sThy3XSr",
        "outputId": "b23eda7a-150c-4d68-aa9a-aa6c26155a82"
      },
      "source": [
        "plot(accuracy_check_model_2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldsJg52PTDPq"
      },
      "source": [
        "Model is not overfitting and we get a best validation accuracy of ~80% and training accuracy of ~82%. Next we will try to reduce the filter size and image resolution and see if get better results. Moreover since we see minor oscillations in loss, let's try lowering the learning rate to 0.0002"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qrMlLsVTSA7"
      },
      "source": [
        "## Model 3 - Reduce filter size to (2,2,2) and image res to 120 x 120"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkPpJFg3TRLh"
      },
      "source": [
        "Conv3D2.clear_session(Conv3D2_model)\r\n",
        "class ModelConv3D3(ModelBuilder):\r\n",
        "    \r\n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\r\n",
        "\r\n",
        "        model = Sequential()\r\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\r\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Flatten())\r\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(dropout))\r\n",
        "\r\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(dropout))\r\n",
        "\r\n",
        "\r\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\r\n",
        "\r\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\r\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\r\n",
        "        return model"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk9L9pt7UBB1",
        "outputId": "4d810987-7893-4c26-ea49-a89d922439ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\r\n",
        "Conv3D3=ModelConv3D3()\r\n",
        "Conv3D3.initialize_src_path(main_folder)\r\n",
        "Conv3D3.initialize_image_properties(image_height=120,image_width=120)\r\n",
        "Conv3D3.initialize_hyperparams(frames_to_sample=16,batch_size=30,num_epochs=30)\r\n",
        "Conv3D3_model=Conv3D3.define_model(filtersize=(2,2,2),dense_neurons=256,dropout=0.5)\r\n",
        "Conv3D3_model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 16, 120, 120, 16)  400       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 16, 120, 120, 16)  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 16, 120, 120, 16)  64        \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 8, 60, 60, 16)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 8, 60, 60, 32)     4128      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 8, 60, 60, 32)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 60, 60, 32)     128       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 4, 30, 30, 32)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 4, 30, 30, 64)     16448     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 4, 30, 30, 64)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 4, 30, 30, 64)     256       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 2, 15, 15, 64)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 2, 15, 15, 128)    65664     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2, 15, 15, 128)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 15, 15, 128)    512       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 1, 7, 7, 128)      0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               1605888   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 1,762,613\n",
            "Trainable params: 1,761,109\n",
            "Non-trainable params: 1,504\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW17sf6iUcQh",
        "outputId": "6905ca03-001f-407e-f645-03a580ff1fd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "##tf.compat.v1.enable_eager_execution()\r\n",
        "print(tf.executing_eagerly())\r\n",
        "print(\"Total Params:\", Conv3D3_model.count_params())\r\n",
        "accuracy_check_model3=Conv3D3.train_model(Conv3D3_model,augment_data=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "Total Params: 1762613\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/30\n",
            "23/23 [==============================] - ETA: 0s - batch: 11.0000 - size: 57.6522 - loss: 2.1736 - categorical_accuracy: 0.3409\n",
            "Epoch 00001: saving model to model_init_2021-03-1613_57_21.995414/model-00001-2.17355-0.34087-2.05905-0.21000.h5\n",
            "683\n",
            "23/23 [==============================] - 223s 10s/step - batch: 11.0000 - size: 57.6522 - loss: 2.1736 - categorical_accuracy: 0.3409 - val_loss: 2.0590 - val_categorical_accuracy: 0.2100\n",
            "Epoch 2/30\n",
            "10/23 [============>.................] - ETA: 1:47 - batch: 4.5000 - size: 60.0000 - loss: 1.6188 - categorical_accuracy: 0.4667"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}