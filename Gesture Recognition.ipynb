{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import abc\n",
    "from sys import getsizeof\n",
    "import shutil\n",
    "import abc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os , shutil\n",
    "for f in glob.glob(\"model_init*\"):\n",
    "    shutil.rmtree(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this block, you read the folder names for training and validation. You also set the batch_size here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the entire dataset is placed in below directory\n",
    "main_folder='Project_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(Model):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(Model.history['loss'])   \n",
    "    axes[0].plot(Model.history['val_loss'])\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "\n",
    "    axes[1].plot(Model.history['categorical_accuracy'])   \n",
    "    axes[1].plot(Model.history['val_categorical_accuracy'])\n",
    "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# referred ABC library use case from this link https://riptutorial.com/python/example/23083/why-how-to-use-abcmeta-and--abstractmethod\n",
    "\n",
    "class ModelBuilder(metaclass= abc.ABCMeta):\n",
    "    \n",
    "    def initialize_src_path(self,main_folder):\n",
    "        self.train_doc = np.random.permutation(open(main_folder + '/' + 'train.csv').readlines())\n",
    "        self.val_doc = np.random.permutation(open(main_folder + '/' + 'val.csv').readlines())\n",
    "        self.train_path = main_folder + '/' + 'train'\n",
    "        self.val_path =  main_folder + '/' + 'val'\n",
    "        self.num_train_sequences = len(self.train_doc)\n",
    "        self.num_val_sequences = len(self.val_doc)\n",
    "        \n",
    "    def initialize_image_properties(self,image_height=100,image_width=100):\n",
    "        self.image_height=image_height\n",
    "        self.image_width=image_width\n",
    "        self.channels=3\n",
    "        self.num_classes=5\n",
    "        self.total_frames=30\n",
    "          \n",
    "    def initialize_hyperparams(self,frames_to_sample=30,batch_size=40,num_epochs=20):\n",
    "        self.frames_to_sample=frames_to_sample\n",
    "        self.batch_size=batch_size\n",
    "        self.num_epochs=num_epochs\n",
    "        \n",
    "        \n",
    "    def generator(self,source_path, folder_list, augment=False):\n",
    "        img_idx = np.round(np.linspace(0,self.total_frames-1,self.frames_to_sample)).astype(int)\n",
    "        batch_size=self.batch_size\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(t)//batch_size\n",
    "        \n",
    "            for batch in range(num_batches): \n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,batch,batch_size,img_idx,augment)\n",
    "                yield batch_data, batch_labels \n",
    "\n",
    "            remaining_seq=len(t)%batch_size\n",
    "        \n",
    "            if (remaining_seq != 0):\n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,num_batches,batch_size,img_idx,augment,remaining_seq)\n",
    "                yield batch_data, batch_labels \n",
    "    \n",
    "    \n",
    "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
    "    \n",
    "        seq_len = remaining_seq if remaining_seq else batch_size\n",
    "    \n",
    "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
    "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
    "    \n",
    "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
    "\n",
    "        \n",
    "        for folder in range(seq_len): \n",
    "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
    "            for idx,item in enumerate(img_idx): \n",
    "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                image_resized=imresize(image,(self.image_height,self.image_width,3))\n",
    "            \n",
    "\n",
    "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "            \n",
    "                if (augment):\n",
    "                    shifted = cv2.warpAffine(image, \n",
    "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
    "                                            (image.shape[1], image.shape[0]))\n",
    "                    \n",
    "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
    "                    \n",
    "                    cropped=shifted[x0:x1,y0:y1,:]\n",
    "                    \n",
    "                    image_resized=imresize(cropped,(self.image_height,self.image_width,3))\n",
    "            \n",
    "                    batch_data_aug[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                    batch_data_aug[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                    batch_data_aug[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "                \n",
    "            \n",
    "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "    \n",
    "        if (augment):\n",
    "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
    "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
    "\n",
    "        \n",
    "        return(batch_data,batch_labels)\n",
    "    \n",
    "    \n",
    "    def train_model(self, model, augment_data=False):\n",
    "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
    "        val_generator = self.generator(self.val_path, self.val_doc)\n",
    "\n",
    "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "        \n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
    "        callbacks_list = [checkpoint, LR]\n",
    "\n",
    "        if (self.num_train_sequences%self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
    "        else:\n",
    "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
    "\n",
    "        if (self.num_val_sequences%self.batch_size) == 0:\n",
    "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
    "        else:\n",
    "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
    "    \n",
    "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
    "                            callbacks=callbacks_list, validation_data=val_generator, \n",
    "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "        return history\n",
    "\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def define_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConv3D1(ModelBuilder):\n",
    "    \n",
    "    def define_model(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(64,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam()\n",
    "        #optimiser = 'sgd'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 30, 160, 160, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 30, 160, 160, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 160, 160, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 15, 80, 80, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 15, 80, 80, 32)    4128      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 15, 80, 80, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 15, 80, 80, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 7, 40, 40, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 7, 40, 40, 64)     16448     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 40, 40, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 40, 40, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 3, 20, 20, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 3, 20, 20, 128)    65664     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 20, 20, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 20, 20, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 1, 10, 10, 128)    0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 1,736,389\n",
      "Trainable params: 1,735,525\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Conv3D1=ModelConv3D1()\n",
    "Conv3D1.initialize_src_path(main_folder)\n",
    "Conv3D1.initialize_image_properties(image_height=160,image_width=160)\n",
    "Conv3D1.initialize_hyperparams(frames_to_sample=30,batch_size=30,num_epochs=1)\n",
    "Conv3D1_model=Conv3D1.define_model()\n",
    "Conv3D1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0315 11:25:08.159296 140545046239040 callbacks.py:1071] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "W0315 11:25:08.161027 140545046239040 deprecation.py:323] From <ipython-input-7-c85facc09113>:122: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - ETA: 0s - loss: 1.5901 - categorical_accuracy: 0.4284\n",
      "Epoch 00001: saving model to model_init_2021-03-1511_25_08.158874/model-00001-1.59008-0.42836-2.63335-0.21000.h5\n",
      "23/23 [==============================] - 204s 9s/step - loss: 1.5901 - categorical_accuracy: 0.4284 - val_loss: 2.6334 - val_categorical_accuracy: 0.2100 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd29815f080>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv3D1.train_model(Conv3D1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_4 (Conv3D)            (None, 30, 160, 160, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30, 160, 160, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 160, 160, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 15, 80, 80, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 15, 80, 80, 32)    4128      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 15, 80, 80, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 15, 80, 80, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 7, 40, 40, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 7, 40, 40, 64)     16448     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 7, 40, 40, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 7, 40, 40, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 3, 20, 20, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 3, 20, 20, 128)    65664     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 3, 20, 20, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 3, 20, 20, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 1, 10, 10, 128)    0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 1,736,389\n",
      "Trainable params: 1,735,525\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Conv3D1_bs40=ModelConv3D1()\n",
    "Conv3D1_bs40.initialize_src_path(main_folder)\n",
    "Conv3D1_bs40.initialize_image_properties(image_height=160,image_width=160)\n",
    "Conv3D1_bs40.initialize_hyperparams(frames_to_sample=30,batch_size=40,num_epochs=1)\n",
    "Conv3D1_model_bs40=Conv3D1_bs40.define_model()\n",
    "Conv3D1_model_bs40.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Got below memory exhaust error with image resolution of 160x160, 30 frames and a batch_size of 40\n",
    "ResourceExhaustedError:  OOM when allocating tensor with shape[40,16,15,80,80] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
    "\t [[node gradient_tape/sequential_2/max_pooling3d_8/MaxPool3D/MaxPool3DGrad (defined at <ipython-input-11-c85facc09113>:122) ]]\n",
    "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
    " [Op:__inference_train_function_7489]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory util is 3.662109524011612 Gigs\n"
     ]
    }
   ],
   "source": [
    "print(\"Memory util is {} Gigs\". format(getsizeof(np.zeros((40,16,30,160,160)))/(1024*1024*1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0315 11:28:59.951972 140545046239040 callbacks.py:1071] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 1736389\n",
      "Epoch 1/3\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.6057 - categorical_accuracy: 0.4133\n",
      "Epoch 00001: saving model to model_init_2021-03-1511_28_59.951207/model-00001-1.60569-0.41327-2.13461-0.21000.h5\n",
      "23/23 [==============================] - 58s 3s/step - loss: 1.6057 - categorical_accuracy: 0.4133 - val_loss: 2.1346 - val_categorical_accuracy: 0.2100 - lr: 0.0010\n",
      "Epoch 2/3\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.1257 - categorical_accuracy: 0.5671\n",
      "Epoch 00002: saving model to model_init_2021-03-1511_28_59.951207/model-00002-1.12573-0.56712-4.76754-0.18000.h5\n",
      "23/23 [==============================] - 58s 3s/step - loss: 1.1257 - categorical_accuracy: 0.5671 - val_loss: 4.7675 - val_categorical_accuracy: 0.1800 - lr: 0.0010\n",
      "Epoch 3/3\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.8557 - categorical_accuracy: 0.6621\n",
      "Epoch 00003: saving model to model_init_2021-03-1511_28_59.951207/model-00003-0.85571-0.66214-6.12139-0.11000.h5\n",
      "23/23 [==============================] - 57s 2s/step - loss: 0.8557 - categorical_accuracy: 0.6621 - val_loss: 6.1214 - val_categorical_accuracy: 0.1100 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd290034278>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_src_path(main_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=30,num_epochs=3)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0315 11:32:02.970877 140545046239040 callbacks.py:1071] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 687813\n",
      "Epoch 1/2\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.7915 - categorical_accuracy: 0.3560\n",
      "Epoch 00001: saving model to model_init_2021-03-1511_32_02.970349/model-00001-1.79150-0.35596-2.34787-0.21000.h5\n",
      "23/23 [==============================] - 90s 4s/step - loss: 1.7915 - categorical_accuracy: 0.3560 - val_loss: 2.3479 - val_categorical_accuracy: 0.2100 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.1892 - categorical_accuracy: 0.5370\n",
      "Epoch 00002: saving model to model_init_2021-03-1511_32_02.970349/model-00002-1.18918-0.53695-4.51897-0.16000.h5\n",
      "23/23 [==============================] - 91s 4s/step - loss: 1.1892 - categorical_accuracy: 0.5370 - val_loss: 4.5190 - val_categorical_accuracy: 0.1600 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd248451e80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_src_path(main_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=30,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0315 11:35:12.400348 140545046239040 callbacks.py:1071] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 687813\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.5725 - categorical_accuracy: 0.3816\n",
      "Epoch 00001: saving model to model_init_2021-03-1511_35_12.399726/model-00001-1.57246-0.38160-1.59263-0.22000.h5\n",
      "12/12 [==============================] - 90s 8s/step - loss: 1.5725 - categorical_accuracy: 0.3816 - val_loss: 1.5926 - val_categorical_accuracy: 0.2200 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.2172 - categorical_accuracy: 0.5309\n",
      "Epoch 00002: saving model to model_init_2021-03-1511_35_12.399726/model-00002-1.21721-0.53092-2.02645-0.16000.h5\n",
      "12/12 [==============================] - 89s 7s/step - loss: 1.2172 - categorical_accuracy: 0.5309 - val_loss: 2.0265 - val_categorical_accuracy: 0.1600 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd24063a198>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_src_path(main_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=60,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0315 11:38:25.032883 140545046239040 callbacks.py:1071] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 687813\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.8245 - categorical_accuracy: 0.3499\n",
      "Epoch 00001: saving model to model_init_2021-03-1511_38_25.032126/model-00001-1.82449-0.34992-1.73380-0.16000.h5\n",
      "12/12 [==============================] - 49s 4s/step - loss: 1.8245 - categorical_accuracy: 0.3499 - val_loss: 1.7338 - val_categorical_accuracy: 0.1600 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "11/12 [==========================>...] - ETA: 3s - loss: 1.2210 - categorical_accuracy: 0.5227\n",
      "Epoch 00002: saving model to model_init_2021-03-1511_38_25.032126/model-00002-1.22527-0.52187-2.99775-0.17000.h5\n",
      "12/12 [==============================] - 48s 4s/step - loss: 1.2253 - categorical_accuracy: 0.5219 - val_loss: 2.9977 - val_categorical_accuracy: 0.1700 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd2400bb898>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_src_path(main_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=60,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0315 11:40:10.377314 140545046239040 callbacks.py:1071] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 687813\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.7715 - categorical_accuracy: 0.3409\n",
      "Epoch 00001: saving model to model_init_2021-03-1511_40_10.376694/model-00001-1.77154-0.34087-1.67701-0.16000.h5\n",
      "9/9 [==============================] - 48s 5s/step - loss: 1.7715 - categorical_accuracy: 0.3409 - val_loss: 1.6770 - val_categorical_accuracy: 0.1600 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.0863 - categorical_accuracy: 0.5716\n",
      "Epoch 00002: saving model to model_init_2021-03-1511_40_10.376694/model-00002-1.08630-0.57164-2.28023-0.22000.h5\n",
      "9/9 [==============================] - 45s 5s/step - loss: 1.0863 - categorical_accuracy: 0.5716 - val_loss: 2.2802 - val_categorical_accuracy: 0.2200 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd1bc266550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_src_path(main_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=80,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0315 11:41:53.864535 140545046239040 callbacks.py:1071] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 1736389\n",
      "Epoch 1/2\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5728 - categorical_accuracy: 0.3982\n",
      "Epoch 00001: saving model to model_init_2021-03-1511_41_53.863774/model-00001-1.57278-0.39819-2.89440-0.24000.h5\n",
      "45/45 [==============================] - 109s 2s/step - loss: 1.5728 - categorical_accuracy: 0.3982 - val_loss: 2.8944 - val_categorical_accuracy: 0.2400 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2310 - categorical_accuracy: 0.5083\n",
      "Epoch 00002: saving model to model_init_2021-03-1511_41_53.863774/model-00002-1.23101-0.50830-4.64528-0.24000.h5\n",
      "45/45 [==============================] - 114s 3s/step - loss: 1.2310 - categorical_accuracy: 0.5083 - val_loss: 4.6453 - val_categorical_accuracy: 0.2400 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd19c47d0f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_src_path(main_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=15,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0315 11:45:45.731355 140545046239040 callbacks.py:1071] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 1736389\n",
      "Epoch 1/2\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.6535 - categorical_accuracy: 0.4133\n",
      "Epoch 00001: saving model to model_init_2021-03-1511_45_45.716693/model-00001-1.65351-0.41327-5.78935-0.21000.h5\n",
      "45/45 [==============================] - 95s 2s/step - loss: 1.6535 - categorical_accuracy: 0.4133 - val_loss: 5.7893 - val_categorical_accuracy: 0.2100 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0873 - categorical_accuracy: 0.5958\n",
      "Epoch 00002: saving model to model_init_2021-03-1511_45_45.716693/model-00002-1.08731-0.59578-8.10266-0.21000.h5\n",
      "45/45 [==============================] - 61s 1s/step - loss: 1.0873 - categorical_accuracy: 0.5958 - val_loss: 8.1027 - val_categorical_accuracy: 0.2100 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd19673bba8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_src_path(main_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=15,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0315 11:48:28.521665 140545046239040 callbacks.py:1071] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 687813\n",
      "Epoch 1/2\n",
      "44/45 [============================>.] - ETA: 0s - loss: 1.6826 - categorical_accuracy: 0.3818\n",
      "Epoch 00001: saving model to model_init_2021-03-1511_48_28.520854/model-00001-1.68579-0.38160-3.02213-0.16000.h5\n",
      "45/45 [==============================] - 47s 1s/step - loss: 1.6858 - categorical_accuracy: 0.3816 - val_loss: 3.0221 - val_categorical_accuracy: 0.1600 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1809 - categorical_accuracy: 0.5294\n",
      "Epoch 00002: saving model to model_init_2021-03-1511_48_28.520854/model-00002-1.18086-0.52941-4.54284-0.13000.h5\n",
      "45/45 [==============================] - 47s 1s/step - loss: 1.1809 - categorical_accuracy: 0.5294 - val_loss: 4.5428 - val_categorical_accuracy: 0.1300 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd122d7e8d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_src_path(main_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=15,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0315 11:50:06.785456 140545046239040 callbacks.py:1071] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 687813\n",
      "Epoch 1/2\n",
      "66/67 [============================>.] - ETA: 0s - loss: 1.7452 - categorical_accuracy: 0.3545\n",
      "Epoch 00001: saving model to model_init_2021-03-1511_50_06.784848/model-00001-1.74835-0.35445-2.21104-0.19000.h5\n",
      "67/67 [==============================] - 48s 709ms/step - loss: 1.7484 - categorical_accuracy: 0.3544 - val_loss: 2.2110 - val_categorical_accuracy: 0.1900 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "66/67 [============================>.] - ETA: 0s - loss: 1.1390 - categorical_accuracy: 0.5561\n",
      "Epoch 00002: saving model to model_init_2021-03-1511_50_06.784848/model-00002-1.14340-0.55505-3.64934-0.21000.h5\n",
      "67/67 [==============================] - 46s 693ms/step - loss: 1.1434 - categorical_accuracy: 0.5551 - val_loss: 3.6493 - val_categorical_accuracy: 0.2100 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd1217a3710>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_src_path(main_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=10,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0315 11:51:45.202952 140545046239040 callbacks.py:1071] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 687813\n",
      "Epoch 1/2\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6941 - categorical_accuracy: 0.3605\n",
      "Epoch 00001: saving model to model_init_2021-03-1511_51_45.202327/model-00001-1.69413-0.36048-2.38097-0.20000.h5\n",
      "67/67 [==============================] - 183s 3s/step - loss: 1.6941 - categorical_accuracy: 0.3605 - val_loss: 2.3810 - val_categorical_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.4527 - categorical_accuracy: 0.4480\n",
      "Epoch 00002: saving model to model_init_2021-03-1511_51_45.202327/model-00002-1.45271-0.44796-2.98445-0.15000.h5\n",
      "67/67 [==============================] - 187s 3s/step - loss: 1.4527 - categorical_accuracy: 0.4480 - val_loss: 2.9845 - val_categorical_accuracy: 0.1500 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd120a207f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_src_path(main_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=10,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0315 11:58:01.496024 140545046239040 callbacks.py:1071] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 1736389\n",
      "Epoch 1/2\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.5371 - categorical_accuracy: 0.4329"
     ]
    }
   ],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_src_path(main_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=10,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_src_path(main_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=10,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_src_path(main_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=40,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "**As we see from the above experiments image resolution and number of frames in sequence have more impact on training time than batch_size.**\n",
    "\n",
    "So experimentations are carried with batch size fixed around 15-40 and changing the resolution and number of image per sequence based on the device memory constraints . Models are designed such that their memory foot print is less than 50 MB which corresponds to 4.3 million parameters assuming the datatype size of parameters to be 12 bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
