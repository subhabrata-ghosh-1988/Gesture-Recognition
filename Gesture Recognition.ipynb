{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import abc\n",
    "from sys import getsizeof\n",
    "import shutil\n",
    "import abc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this block, you read the folder names for training and validation. You also set the batch_size here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the entire dataset is placed in below directory\n",
    "main_folder='Project_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(Model):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(Model.history['loss'])   \n",
    "    axes[0].plot(Model.history['val_loss'])\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "\n",
    "    axes[1].plot(Model.history['categorical_accuracy'])   \n",
    "    axes[1].plot(Model.history['val_categorical_accuracy'])\n",
    "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# referred ABC library use case from this link https://riptutorial.com/python/example/23083/why-how-to-use-abcmeta-and--abstractmethod\n",
    "\n",
    "class ModelBuilder(metaclass= abc.ABCMeta):\n",
    "    \n",
    "    def initialize_src_path(self,main_folder):\n",
    "        self.train_doc = np.random.permutation(open(main_folder + '/' + 'train.csv').readlines())\n",
    "        self.val_doc = np.random.permutation(open(main_folder + '/' + 'val.csv').readlines())\n",
    "        self.train_path = main_folder + '/' + 'train'\n",
    "        self.val_path =  main_folder + '/' + 'val'\n",
    "        self.num_train_sequences = len(self.train_doc)\n",
    "        self.num_val_sequences = len(self.val_doc)\n",
    "        \n",
    "    def initialize_image_properties(self,image_height=100,image_width=100):\n",
    "        self.image_height=image_height\n",
    "        self.image_width=image_width\n",
    "        self.channels=3\n",
    "        self.num_classes=5\n",
    "        self.total_frames=30\n",
    "          \n",
    "    def initialize_hyperparams(self,frames_to_sample=30,batch_size=40,num_epochs=20):\n",
    "        self.frames_to_sample=frames_to_sample\n",
    "        self.batch_size=batch_size\n",
    "        self.num_epochs=num_epochs\n",
    "        \n",
    "        \n",
    "    def generator(self,source_path, folder_list, augment=False):\n",
    "        img_idx = np.round(np.linspace(0,self.total_frames-1,self.frames_to_sample)).astype(int)\n",
    "        batch_size=self.batch_size\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(t)//batch_size\n",
    "        \n",
    "            for batch in range(num_batches): \n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,batch,batch_size,img_idx,augment)\n",
    "                yield batch_data, batch_labels \n",
    "\n",
    "            remaining_seq=len(t)%batch_size\n",
    "        \n",
    "            if (remaining_seq != 0):\n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,num_batches,batch_size,img_idx,augment,remaining_seq)\n",
    "                yield batch_data, batch_labels \n",
    "    \n",
    "    \n",
    "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
    "    \n",
    "        seq_len = remaining_seq if remaining_seq else batch_size\n",
    "    \n",
    "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
    "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
    "    \n",
    "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
    "\n",
    "        \n",
    "        for folder in range(seq_len): \n",
    "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
    "            for idx,item in enumerate(img_idx): \n",
    "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                image_resized=imresize(image,(self.image_height,self.image_width,3))\n",
    "            \n",
    "\n",
    "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "            \n",
    "                if (augment):\n",
    "                    shifted = cv2.warpAffine(image, \n",
    "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
    "                                            (image.shape[1], image.shape[0]))\n",
    "                    \n",
    "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
    "                    \n",
    "                    cropped=shifted[x0:x1,y0:y1,:]\n",
    "                    \n",
    "                    image_resized=imresize(cropped,(self.image_height,self.image_width,3))\n",
    "            \n",
    "                    batch_data_aug[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                    batch_data_aug[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                    batch_data_aug[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "                \n",
    "            \n",
    "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "    \n",
    "        if (augment):\n",
    "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
    "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
    "\n",
    "        \n",
    "        return(batch_data,batch_labels)\n",
    "    \n",
    "    \n",
    "    def train_model(self, model, augment_data=False):\n",
    "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
    "        val_generator = self.generator(self.val_path, self.val_doc)\n",
    "\n",
    "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "        \n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
    "        callbacks_list = [checkpoint, LR]\n",
    "\n",
    "        if (self.num_train_sequences%self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
    "        else:\n",
    "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
    "\n",
    "        if (self.num_val_sequences%self.batch_size) == 0:\n",
    "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
    "        else:\n",
    "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
    "    \n",
    "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
    "                            callbacks=callbacks_list, validation_data=val_generator, \n",
    "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "        return history\n",
    "\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def define_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConv3D1(ModelBuilder):\n",
    "    \n",
    "    def define_model(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(64,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam()\n",
    "        #optimiser = 'sgd'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 30, 160, 160, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 30, 160, 160, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 160, 160, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 15, 80, 80, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 15, 80, 80, 32)    4128      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 15, 80, 80, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 15, 80, 80, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 7, 40, 40, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 7, 40, 40, 64)     16448     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 40, 40, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 40, 40, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 3, 20, 20, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 3, 20, 20, 128)    65664     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 20, 20, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 20, 20, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 1, 10, 10, 128)    0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 1,736,389\n",
      "Trainable params: 1,735,525\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Conv3D1=ModelConv3D1()\n",
    "Conv3D1.initialize_src_path(main_folder)\n",
    "Conv3D1.initialize_image_properties(image_height=160,image_width=160)\n",
    "Conv3D1.initialize_hyperparams(frames_to_sample=30,batch_size=30,num_epochs=1)\n",
    "Conv3D1_model=Conv3D1.define_model()\n",
    "Conv3D1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0315 04:44:32.192235 140707613259584 callbacks.py:1071] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "W0315 04:44:32.193046 140707613259584 deprecation.py:323] From <ipython-input-11-c85facc09113>:122: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - ETA: 0s - loss: 1.5943 - categorical_accuracy: 0.4208\n",
      "Epoch 00001: saving model to model_init_2021-03-1504_44_32.170535/model-00001-1.59430-0.42081-2.50116-0.21000.h5\n",
      "23/23 [==============================] - 190s 8s/step - loss: 1.5943 - categorical_accuracy: 0.4208 - val_loss: 2.5012 - val_categorical_accuracy: 0.2100 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff8684e8940>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv3D1.train_model(Conv3D1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_8 (Conv3D)            (None, 30, 160, 160, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 160, 160, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 30, 160, 160, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 15, 80, 80, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 15, 80, 80, 32)    4128      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 15, 80, 80, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 15, 80, 80, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 7, 40, 40, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 7, 40, 40, 64)     16448     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 7, 40, 40, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 7, 40, 40, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 3, 20, 20, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 3, 20, 20, 128)    65664     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 3, 20, 20, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 3, 20, 20, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 1, 10, 10, 128)    0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 1,736,389\n",
      "Trainable params: 1,735,525\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Conv3D1_bs40=ModelConv3D1()\n",
    "Conv3D1_bs40.initialize_src_path(main_folder)\n",
    "Conv3D1_bs40.initialize_image_properties(image_height=160,image_width=160)\n",
    "Conv3D1_bs40.initialize_hyperparams(frames_to_sample=30,batch_size=40,num_epochs=1)\n",
    "Conv3D1_model_bs40=Conv3D1_bs40.define_model()\n",
    "Conv3D1_model_bs40.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Got below memory exhaust error with image resolution of 160x160, 30 frames and a batch_size of 40\n",
    "ResourceExhaustedError:  OOM when allocating tensor with shape[40,16,15,80,80] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
    "\t [[node gradient_tape/sequential_2/max_pooling3d_8/MaxPool3D/MaxPool3DGrad (defined at <ipython-input-11-c85facc09113>:122) ]]\n",
    "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
    " [Op:__inference_train_function_7489]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory util is 3.662109524011612 Gigs\n"
     ]
    }
   ],
   "source": [
    "print(\"Memory util is {} Gigs\". format(getsizeof(np.zeros((40,16,30,160,160)))/(1024*1024*1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
