{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Gesture Recognition.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhabrata-ghosh-1988/Gesture-Recognition/blob/main/Gesture%20Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7ZfgtjxNVrR"
      },
      "source": [
        "# Gesture Recognition\n",
        "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-eH5pKuNVrV"
      },
      "source": [
        "## Import libraries\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy import misc\n",
        "from imageio import imread\n",
        "import cv2\n",
        "from skimage import transform,io\n",
        "import datetime\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import abc\n",
        "from sys import getsizeof\n",
        "import shutil\n",
        "import abc\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J94bqUhVNVrW"
      },
      "source": [
        "import glob, os , shutil\n",
        "for f in glob.glob(\"/content/model_init*\"):\n",
        "    shutil.rmtree(f)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Ubj-HfSRY3"
      },
      "source": [
        "## remove the existing zip file\r\n",
        "shutil.rmtree('/content/Project_data.zip', ignore_errors=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4ty5a19SiNl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "bc6b7245-50e4-4c9d-a390-4326a8ba9905"
      },
      "source": [
        "## Initiate the file download\r\n",
        "!pip install gdown\r\n",
        "import gdown\r\n",
        "url=\"https://drive.google.com/uc?id=1kM4V7pnLjGbuCaDpfBNHig99gr2rdqyJ\"\r\n",
        "output = \"Project_data.zip\"\r\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kM4V7pnLjGbuCaDpfBNHig99gr2rdqyJ\n",
            "To: /content/Project_data.zip\n",
            "1.71GB [00:47, 36.1MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Project_data.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-fwe5jbTX8r"
      },
      "source": [
        "## unzip the downloaded folder\r\n",
        "shutil.rmtree('/content/Project_data', ignore_errors=True)\r\n",
        "shutil.unpack_archive(\"Project_data.zip\", \"Project_data\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIQHPGi_NVrX"
      },
      "source": [
        "We set the random seed so that the results don't vary drastically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci_N-NnWNVrZ"
      },
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)\n",
        "#tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bWyzW_oNVrZ"
      },
      "source": [
        "**In this block, you read the folder names for training and validation. You also set the batch_size here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyTupvi3NVrb"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCjeEg_tNVrc"
      },
      "source": [
        "# the entire dataset is placed in below directory\n",
        "main_folder='/content/Project_data/Project_data'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSUMkqaSXcC4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6bb01b58-c61a-4b11-ca94-a31a64c03f2e"
      },
      "source": [
        "## Checking current TF version\r\n",
        "tf.version.VERSION"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REgxbVunNVrd"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3UJmY03NVre"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot(Model):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
        "    axes[0].plot(Model.history['loss'])   \n",
        "    axes[0].plot(Model.history['val_loss'])\n",
        "    axes[0].legend(['loss','val_loss'])\n",
        "\n",
        "    axes[1].plot(Model.history['categorical_accuracy'])   \n",
        "    axes[1].plot(Model.history['val_categorical_accuracy'])\n",
        "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtV6apQQNVrf"
      },
      "source": [
        "## Generator\n",
        "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haSnpGsboLKX"
      },
      "source": [
        "import gc\r\n",
        "class GCCallback(tf.keras.callbacks.Callback):\r\n",
        "      def on_epoch_end(self, epoch, logs=None):\r\n",
        "          print(gc.collect())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YC-BRedNVri"
      },
      "source": [
        "# referred ABC library use case from this link https://riptutorial.com/python/example/23083/why-how-to-use-abcmeta-and--abstractmethod\n",
        "\n",
        "class ModelBuilder(metaclass= abc.ABCMeta):\n",
        "    \n",
        "    def initialize_src_path(self,main_folder):\n",
        "        self.train_doc = np.random.permutation(open(main_folder + '/' + 'train.csv').readlines())\n",
        "        self.val_doc = np.random.permutation(open(main_folder + '/' + 'val.csv').readlines())\n",
        "        self.train_path = main_folder + '/' + 'train'\n",
        "        self.val_path =  main_folder + '/' + 'val'\n",
        "        self.num_train_sequences = len(self.train_doc)\n",
        "        self.num_val_sequences = len(self.val_doc)\n",
        "        \n",
        "    def initialize_image_properties(self,image_height=100,image_width=100):\n",
        "        self.image_height=image_height\n",
        "        self.image_width=image_width\n",
        "        self.channels=3\n",
        "        self.num_classes=5\n",
        "        self.total_frames=30\n",
        "          \n",
        "    def initialize_hyperparams(self,frames_to_sample=30,batch_size=40,num_epochs=20):\n",
        "        self.frames_to_sample=frames_to_sample\n",
        "        self.batch_size=batch_size\n",
        "        self.num_epochs=num_epochs\n",
        "        \n",
        "        \n",
        "    def generator(self,source_path, folder_list, augment=False):\n",
        "        img_idx = np.round(np.linspace(0,self.total_frames-1,self.frames_to_sample)).astype(int)\n",
        "        batch_size=self.batch_size\n",
        "        while True:\n",
        "            t = np.random.permutation(folder_list)\n",
        "            num_batches = len(t)//batch_size\n",
        "        \n",
        "            for batch in range(num_batches): \n",
        "                batch_data, batch_labels= self.one_batch_data(source_path,t,batch,batch_size,img_idx,augment)\n",
        "                yield batch_data, batch_labels \n",
        "\n",
        "            remaining_seq=len(t)%batch_size\n",
        "        \n",
        "            if (remaining_seq != 0):\n",
        "                batch_data, batch_labels= self.one_batch_data(source_path,t,num_batches,batch_size,img_idx,augment,remaining_seq)\n",
        "                yield batch_data, batch_labels \n",
        "    \n",
        "    \n",
        "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
        "    \n",
        "        seq_len = remaining_seq if remaining_seq else batch_size\n",
        "    \n",
        "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
        "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
        "    \n",
        "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
        "\n",
        "        \n",
        "        for folder in range(seq_len): \n",
        "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
        "            for idx,item in enumerate(img_idx): \n",
        "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                image_resized=transform.resize(image,(self.image_height,self.image_width,3))\n",
        "            \n",
        "\n",
        "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
        "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
        "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
        "            \n",
        "                if (augment):\n",
        "                    shifted = cv2.warpAffine(image, \n",
        "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
        "                                            (image.shape[1], image.shape[0]))\n",
        "                    \n",
        "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
        "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
        "                    \n",
        "                    cropped=shifted[x0:x1,y0:y1,:]\n",
        "                    \n",
        "                    image_resized=transform.resize(cropped,(self.image_height,self.image_width,3))\n",
        "            \n",
        "                    batch_data_aug[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
        "                    batch_data_aug[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
        "                    batch_data_aug[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
        "                \n",
        "            \n",
        "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            \n",
        "    \n",
        "        if (augment):\n",
        "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
        "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
        "\n",
        "        \n",
        "        return(batch_data,batch_labels)\n",
        "    \n",
        "    \n",
        "    def train_model(self, model, augment_data=False):\n",
        "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
        "        val_generator = self.generator(self.val_path, self.val_doc)\n",
        "\n",
        "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "        if not os.path.exists(model_name):\n",
        "            os.mkdir(model_name)\n",
        "        \n",
        "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
        "        callbacks_list = [checkpoint, LR, GCCallback()]\n",
        "\n",
        "        if (self.num_train_sequences%self.batch_size) == 0:\n",
        "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
        "        else:\n",
        "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
        "\n",
        "        if (self.num_val_sequences%self.batch_size) == 0:\n",
        "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
        "        else:\n",
        "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
        "    \n",
        "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
        "                            callbacks=callbacks_list, validation_data=val_generator, \n",
        "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
        "        return history\n",
        "\n",
        "    def clear_session(self, model):\n",
        "        del model\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "        tf.compat.v1.reset_default_graph() # TF graph isn't same as Keras graph\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def define_model(self):\n",
        "        pass\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkdCou-eNVri"
      },
      "source": [
        "## Sample Model\n",
        "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1XR94jpNVrk"
      },
      "source": [
        "class ModelConv3D1(ModelBuilder):\n",
        "    \n",
        "    def define_model(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Dense(64,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam()\n",
        "        #optimiser = 'sgd'\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIGA0cbNVrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edeab142-7671-4f4a-c005-eb1ae4e953ea"
      },
      "source": [
        "Conv3D1=ModelConv3D1()\n",
        "Conv3D1.initialize_src_path(main_folder)\n",
        "Conv3D1.initialize_image_properties(image_height=160,image_width=160)\n",
        "Conv3D1.initialize_hyperparams(frames_to_sample=30,batch_size=30,num_epochs=1)\n",
        "Conv3D1_model=Conv3D1.define_model()\n",
        "Conv3D1_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 30, 160, 160, 16)  1312      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 30, 160, 160, 16)  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 30, 160, 160, 16)  64        \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 15, 80, 80, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 15, 80, 80, 32)    4128      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 15, 80, 80, 32)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 15, 80, 80, 32)    128       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 7, 40, 40, 32)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 7, 40, 40, 64)     16448     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 7, 40, 40, 64)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 40, 40, 64)     256       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 3, 20, 20, 64)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 3, 20, 20, 128)    65664     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 3, 20, 20, 128)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 3, 20, 20, 128)    512       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 1, 10, 10, 128)    0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1638528   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 1,736,389\n",
            "Trainable params: 1,735,525\n",
            "Non-trainable params: 864\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eU6XuXdNVrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b67664-1be1-47f1-a50a-74883d0cb2c7"
      },
      "source": [
        "Conv3D1.train_model(Conv3D1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "23/23 [==============================] - ETA: 0s - batch: 11.0000 - size: 28.8261 - loss: 1.5124 - categorical_accuracy: 0.4585 \n",
            "Epoch 00001: saving model to model_init_2021-03-1617_19_52.926030/model-00001-1.51240-0.45852-3.24692-0.21000.h5\n",
            "0\n",
            "23/23 [==============================] - 341s 13s/step - batch: 11.0000 - size: 28.8261 - loss: 1.5124 - categorical_accuracy: 0.4585 - val_loss: 3.2469 - val_categorical_accuracy: 0.2100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f31e2b8d4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaJ-270dCcnY"
      },
      "source": [
        "Conv3D1.clear_session(Conv3D1_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPGUJrJXNVrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664bb7e2-3abf-4726-dee9-b2386588bd87"
      },
      "source": [
        "Conv3D1_bs40=ModelConv3D1()\n",
        "Conv3D1_bs40.initialize_src_path(main_folder)\n",
        "Conv3D1_bs40.initialize_image_properties(image_height=160,image_width=160)\n",
        "Conv3D1_bs40.initialize_hyperparams(frames_to_sample=30,batch_size=40,num_epochs=1)\n",
        "Conv3D1_model_bs40=Conv3D1_bs40.define_model()\n",
        "Conv3D1_model_bs40.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 30, 160, 160, 16)  1312      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 30, 160, 160, 16)  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 30, 160, 160, 16)  64        \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 15, 80, 80, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 15, 80, 80, 32)    4128      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 15, 80, 80, 32)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 15, 80, 80, 32)    128       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 7, 40, 40, 32)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 7, 40, 40, 64)     16448     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 7, 40, 40, 64)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 40, 40, 64)     256       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 3, 20, 20, 64)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 3, 20, 20, 128)    65664     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 3, 20, 20, 128)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 3, 20, 20, 128)    512       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 1, 10, 10, 128)    0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1638528   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 1,736,389\n",
            "Trainable params: 1,735,525\n",
            "Non-trainable params: 864\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHCAyYjiNVro"
      },
      "source": [
        "#### Got below memory exhaust error with image resolution of 160x160, 30 frames and a batch_size of 40\n",
        "ResourceExhaustedError:  OOM when allocating tensor with shape[40,16,15,80,80] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
        "\t [[node gradient_tape/sequential_2/max_pooling3d_8/MaxPool3D/MaxPool3DGrad (defined at <ipython-input-11-c85facc09113>:122) ]]\n",
        "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
        " [Op:__inference_train_function_7489]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7SaHnFVNVro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc96723-b99c-4cf5-de74-090abba71d4e"
      },
      "source": [
        "print(\"Memory util is {} Gigs\". format(getsizeof(np.zeros((40,16,30,160,160)))/(1024*1024*1024)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory util is 3.662109524011612 Gigs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSsKCHtZNVrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb40823-6f73-46dc-d828-6f536990e4f6"
      },
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=30,num_epochs=3)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 1736389\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/3\n",
            "23/23 [==============================] - ETA: 0s - batch: 11.0000 - size: 28.8261 - loss: 1.4579 - categorical_accuracy: 0.4480\n",
            "Epoch 00001: saving model to model_init_2021-03-1617_25_47.436925/model-00001-1.45787-0.44796-3.58210-0.16000.h5\n",
            "4\n",
            "23/23 [==============================] - 198s 8s/step - batch: 11.0000 - size: 28.8261 - loss: 1.4579 - categorical_accuracy: 0.4480 - val_loss: 3.5821 - val_categorical_accuracy: 0.1600\n",
            "Epoch 2/3\n",
            "23/23 [==============================] - ETA: 0s - batch: 11.0000 - size: 28.8261 - loss: 0.9643 - categorical_accuracy: 0.6275\n",
            "Epoch 00002: saving model to model_init_2021-03-1617_25_47.436925/model-00002-0.96433-0.62745-7.10073-0.18000.h5\n",
            "0\n",
            "23/23 [==============================] - 153s 7s/step - batch: 11.0000 - size: 28.8261 - loss: 0.9643 - categorical_accuracy: 0.6275 - val_loss: 7.1007 - val_categorical_accuracy: 0.1800\n",
            "Epoch 3/3\n",
            "23/23 [==============================] - ETA: 0s - batch: 11.0000 - size: 28.8261 - loss: 0.7267 - categorical_accuracy: 0.7255\n",
            "Epoch 00003: saving model to model_init_2021-03-1617_25_47.436925/model-00003-0.72666-0.72549-10.37415-0.11000.h5\n",
            "0\n",
            "23/23 [==============================] - 157s 7s/step - batch: 11.0000 - size: 28.8261 - loss: 0.7267 - categorical_accuracy: 0.7255 - val_loss: 10.3741 - val_categorical_accuracy: 0.1100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f31e28b1050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx0kjX0PNVrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e684d798-9e4f-42e0-bc73-2c872d5c33b8"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=30,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 687813\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "23/23 [==============================] - ETA: 0s - batch: 11.0000 - size: 28.8261 - loss: 1.6429 - categorical_accuracy: 0.4012 \n",
            "Epoch 00001: saving model to model_init_2021-03-1617_34_18.525372/model-00001-1.64291-0.40121-1.79644-0.21000.h5\n",
            "48\n",
            "23/23 [==============================] - 294s 13s/step - batch: 11.0000 - size: 28.8261 - loss: 1.6429 - categorical_accuracy: 0.4012 - val_loss: 1.7964 - val_categorical_accuracy: 0.2100\n",
            "Epoch 2/2\n",
            "23/23 [==============================] - ETA: 0s - batch: 11.0000 - size: 28.8261 - loss: 1.1605 - categorical_accuracy: 0.5566\n",
            "Epoch 00002: saving model to model_init_2021-03-1617_34_18.525372/model-00002-1.16052-0.55656-2.92926-0.16000.h5\n",
            "0\n",
            "23/23 [==============================] - 246s 11s/step - batch: 11.0000 - size: 28.8261 - loss: 1.1605 - categorical_accuracy: 0.5566 - val_loss: 2.9293 - val_categorical_accuracy: 0.1600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f31e232df90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xReB_wtlNVrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce7ffabf-3db9-468f-8e37-fc1c7a3ea23d"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=60,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 687813\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "12/12 [==============================] - ETA: 0s - batch: 5.5000 - size: 55.2500 - loss: 1.5702 - categorical_accuracy: 0.4148 \n",
            "Epoch 00001: saving model to model_init_2021-03-1617_43_22.305275/model-00001-1.57016-0.41478-1.65085-0.16000.h5\n",
            "48\n",
            "12/12 [==============================] - 294s 24s/step - batch: 5.5000 - size: 55.2500 - loss: 1.5702 - categorical_accuracy: 0.4148 - val_loss: 1.6508 - val_categorical_accuracy: 0.1600\n",
            "Epoch 2/2\n",
            "12/12 [==============================] - ETA: 0s - batch: 5.5000 - size: 55.2500 - loss: 1.2213 - categorical_accuracy: 0.5596 \n",
            "Epoch 00002: saving model to model_init_2021-03-1617_43_22.305275/model-00002-1.22129-0.55958-2.46422-0.16000.h5\n",
            "0\n",
            "12/12 [==============================] - 255s 23s/step - batch: 5.5000 - size: 55.2500 - loss: 1.2213 - categorical_accuracy: 0.5596 - val_loss: 2.4642 - val_categorical_accuracy: 0.1600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f31e1e44f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoKopL3YNVry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca951448-4f74-477b-ce70-813d98224483"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=60,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 687813\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "12/12 [==============================] - ETA: 0s - batch: 5.5000 - size: 55.2500 - loss: 1.7014 - categorical_accuracy: 0.3665 \n",
            "Epoch 00001: saving model to model_init_2021-03-1617_52_34.815078/model-00001-1.70136-0.36652-1.71886-0.17000.h5\n",
            "48\n",
            "12/12 [==============================] - 179s 13s/step - batch: 5.5000 - size: 55.2500 - loss: 1.7014 - categorical_accuracy: 0.3665 - val_loss: 1.7189 - val_categorical_accuracy: 0.1700\n",
            "Epoch 2/2\n",
            "12/12 [==============================] - ETA: 0s - batch: 5.5000 - size: 55.2500 - loss: 1.4547 - categorical_accuracy: 0.5023 \n",
            "Epoch 00002: saving model to model_init_2021-03-1617_52_34.815078/model-00002-1.45466-0.50226-2.78275-0.17000.h5\n",
            "0\n",
            "12/12 [==============================] - 136s 12s/step - batch: 5.5000 - size: 55.2500 - loss: 1.4547 - categorical_accuracy: 0.5023 - val_loss: 2.7828 - val_categorical_accuracy: 0.1700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f312f57f550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHABNT4GNVry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "321eafc0-7608-4e19-a099-106c914830a4"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=80,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 687813\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "9/9 [==============================] - ETA: 0s - batch: 4.0000 - size: 73.6667 - loss: 1.7387 - categorical_accuracy: 0.3786 \n",
            "Epoch 00001: saving model to model_init_2021-03-1617_57_53.433839/model-00001-1.73868-0.37858-1.61466-0.21000.h5\n",
            "48\n",
            "9/9 [==============================] - 166s 17s/step - batch: 4.0000 - size: 73.6667 - loss: 1.7387 - categorical_accuracy: 0.3786 - val_loss: 1.6147 - val_categorical_accuracy: 0.2100\n",
            "Epoch 2/2\n",
            "9/9 [==============================] - ETA: 0s - batch: 4.0000 - size: 73.6667 - loss: 1.1627 - categorical_accuracy: 0.5732 \n",
            "Epoch 00002: saving model to model_init_2021-03-1617_57_53.433839/model-00002-1.16269-0.57315-2.01522-0.16000.h5\n",
            "0\n",
            "9/9 [==============================] - 138s 17s/step - batch: 4.0000 - size: 73.6667 - loss: 1.1627 - categorical_accuracy: 0.5732 - val_loss: 2.0152 - val_categorical_accuracy: 0.1600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f313205ff50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2T9W4HyNVrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "936f3dbd-4e00-4db7-9c0d-2bd2a4dcdbbf"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=15,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 1736389\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "45/45 [==============================] - ETA: 0s - batch: 22.0000 - size: 14.7333 - loss: 1.5972 - categorical_accuracy: 0.4284\n",
            "Epoch 00001: saving model to model_init_2021-03-1618_03_00.910522/model-00001-1.59724-0.42836-5.32844-0.21000.h5\n",
            "48\n",
            "45/45 [==============================] - 334s 7s/step - batch: 22.0000 - size: 14.7333 - loss: 1.5972 - categorical_accuracy: 0.4284 - val_loss: 5.3284 - val_categorical_accuracy: 0.2100\n",
            "Epoch 2/2\n",
            "45/45 [==============================] - ETA: 0s - batch: 22.0000 - size: 14.7333 - loss: 1.1243 - categorical_accuracy: 0.5882\n",
            "Epoch 00002: saving model to model_init_2021-03-1618_03_00.910522/model-00002-1.12431-0.58824-9.55669-0.23000.h5\n",
            "0\n",
            "45/45 [==============================] - 284s 6s/step - batch: 22.0000 - size: 14.7333 - loss: 1.1243 - categorical_accuracy: 0.5882 - val_loss: 9.5567 - val_categorical_accuracy: 0.2300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f31a34bd850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25WU3xHcNVrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9246c9d0-c253-442c-ba3e-1f6ca5d6260e"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=15,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 1736389\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "45/45 [==============================] - ETA: 0s - batch: 22.0000 - size: 14.7333 - loss: 1.5379 - categorical_accuracy: 0.4253\n",
            "Epoch 00001: saving model to model_init_2021-03-1618_13_23.156274/model-00001-1.53788-0.42534-6.44199-0.15000.h5\n",
            "48\n",
            "45/45 [==============================] - 180s 4s/step - batch: 22.0000 - size: 14.7333 - loss: 1.5379 - categorical_accuracy: 0.4253 - val_loss: 6.4420 - val_categorical_accuracy: 0.1500\n",
            "Epoch 2/2\n",
            "45/45 [==============================] - ETA: 0s - batch: 22.0000 - size: 14.7333 - loss: 1.0118 - categorical_accuracy: 0.6094\n",
            "Epoch 00002: saving model to model_init_2021-03-1618_13_23.156274/model-00002-1.01183-0.60935-9.79796-0.13000.h5\n",
            "0\n",
            "45/45 [==============================] - 151s 3s/step - batch: 22.0000 - size: 14.7333 - loss: 1.0118 - categorical_accuracy: 0.6094 - val_loss: 9.7980 - val_categorical_accuracy: 0.1300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f313158eb50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPzFJDfUNVr0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4afdc45-e433-4b7c-8c80-03c5289af80c"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=15,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 687813\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "45/45 [==============================] - ETA: 0s - batch: 22.0000 - size: 14.7333 - loss: 1.7739 - categorical_accuracy: 0.3741\n",
            "Epoch 00001: saving model to model_init_2021-03-1618_18_57.526314/model-00001-1.77390-0.37406-2.06810-0.21000.h5\n",
            "48\n",
            "45/45 [==============================] - 155s 3s/step - batch: 22.0000 - size: 14.7333 - loss: 1.7739 - categorical_accuracy: 0.3741 - val_loss: 2.0681 - val_categorical_accuracy: 0.2100\n",
            "Epoch 2/2\n",
            "45/45 [==============================] - ETA: 0s - batch: 22.0000 - size: 14.7333 - loss: 1.2061 - categorical_accuracy: 0.5324\n",
            "Epoch 00002: saving model to model_init_2021-03-1618_18_57.526314/model-00002-1.20606-0.53243-4.29833-0.13000.h5\n",
            "0\n",
            "45/45 [==============================] - 134s 3s/step - batch: 22.0000 - size: 14.7333 - loss: 1.2061 - categorical_accuracy: 0.5324 - val_loss: 4.2983 - val_categorical_accuracy: 0.1300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f312eb62c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdQ6Aed-NVr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5373637f-b397-4727-b826-50ed8585ada2"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=10,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 687813\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.7582 - categorical_accuracy: 0.3741 \n",
            "Epoch 00001: saving model to model_init_2021-03-1618_23_49.971391/model-00001-1.75815-0.37406-3.13596-0.17000.h5\n",
            "48\n",
            "67/67 [==============================] - 160s 2s/step - batch: 33.0000 - size: 9.8955 - loss: 1.7582 - categorical_accuracy: 0.3741 - val_loss: 3.1360 - val_categorical_accuracy: 0.1700\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.2933 - categorical_accuracy: 0.4691 \n",
            "Epoch 00002: saving model to model_init_2021-03-1618_23_49.971391/model-00002-1.29329-0.46908-5.00531-0.16000.h5\n",
            "0\n",
            "67/67 [==============================] - 134s 2s/step - batch: 33.0000 - size: 9.8955 - loss: 1.2933 - categorical_accuracy: 0.4691 - val_loss: 5.0053 - val_categorical_accuracy: 0.1600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f31309f8490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OYsvNb7NVr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b86800ed-4c47-43d6-a2a2-056f3e09423a"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=10,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 687813\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.7235 - categorical_accuracy: 0.3741 \n",
            "Epoch 00001: saving model to model_init_2021-03-1618_28_46.253421/model-00001-1.72346-0.37406-7.84060-0.21000.h5\n",
            "48\n",
            "67/67 [==============================] - 288s 4s/step - batch: 33.0000 - size: 9.8955 - loss: 1.7235 - categorical_accuracy: 0.3741 - val_loss: 7.8406 - val_categorical_accuracy: 0.2100\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.2003 - categorical_accuracy: 0.5400 \n",
            "Epoch 00002: saving model to model_init_2021-03-1618_28_46.253421/model-00002-1.20034-0.53997-12.12701-0.20000.h5\n",
            "0\n",
            "67/67 [==============================] - 258s 4s/step - batch: 33.0000 - size: 9.8955 - loss: 1.2003 - categorical_accuracy: 0.5400 - val_loss: 12.1270 - val_categorical_accuracy: 0.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f31e08e5b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D4BJx6gNVr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cce9353-bcbb-4976-c397-4d939977213d"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=10,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 1736389\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.5896 - categorical_accuracy: 0.3891 \n",
            "Epoch 00001: saving model to model_init_2021-03-1618_37_55.570999/model-00001-1.58957-0.38914-6.22037-0.16000.h5\n",
            "48\n",
            "67/67 [==============================] - 338s 5s/step - batch: 33.0000 - size: 9.8955 - loss: 1.5896 - categorical_accuracy: 0.3891 - val_loss: 6.2204 - val_categorical_accuracy: 0.1600\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.2065 - categorical_accuracy: 0.5234 \n",
            "Epoch 00002: saving model to model_init_2021-03-1618_37_55.570999/model-00002-1.20654-0.52338-9.05409-0.16000.h5\n",
            "0\n",
            "67/67 [==============================] - 290s 4s/step - batch: 33.0000 - size: 9.8955 - loss: 1.2065 - categorical_accuracy: 0.5234 - val_loss: 9.0541 - val_categorical_accuracy: 0.1600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f31e03bda10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo38TA_HNVr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a25c53e2-3be1-465a-ec8a-4feb2fffedb0"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=10,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 1736389\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.6350 - categorical_accuracy: 0.3967 \n",
            "Epoch 00001: saving model to model_init_2021-03-1618_48_26.069391/model-00001-1.63499-0.39668-4.31884-0.22000.h5\n",
            "48\n",
            "67/67 [==============================] - 181s 3s/step - batch: 33.0000 - size: 9.8955 - loss: 1.6350 - categorical_accuracy: 0.3967 - val_loss: 4.3188 - val_categorical_accuracy: 0.2200\n",
            "Epoch 2/2\n",
            "67/67 [==============================] - ETA: 0s - batch: 33.0000 - size: 9.8955 - loss: 1.3540 - categorical_accuracy: 0.4827 \n",
            "Epoch 00002: saving model to model_init_2021-03-1618_48_26.069391/model-00002-1.35397-0.48265-7.07003-0.17000.h5\n",
            "0\n",
            "67/67 [==============================] - 157s 2s/step - batch: 33.0000 - size: 9.8955 - loss: 1.3540 - categorical_accuracy: 0.4827 - val_loss: 7.0700 - val_categorical_accuracy: 0.1700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3132503590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns4lmR9bNVr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64bb6035-a799-4261-f8e7-9d2d8a94563c"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\n",
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_src_path(main_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=40,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 1736389\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/2\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 1.6316 - categorical_accuracy: 0.4268\n",
            "Epoch 00001: saving model to model_init_2021-03-1618_54_06.533408/model-00001-1.63161-0.42685-3.55708-0.21000.h5\n",
            "48\n",
            "17/17 [==============================] - 181s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 1.6316 - categorical_accuracy: 0.4268 - val_loss: 3.5571 - val_categorical_accuracy: 0.2100\n",
            "Epoch 2/2\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 1.0408 - categorical_accuracy: 0.6018\n",
            "Epoch 00002: saving model to model_init_2021-03-1618_54_06.533408/model-00002-1.04082-0.60181-7.17712-0.18000.h5\n",
            "0\n",
            "17/17 [==============================] - 156s 10s/step - batch: 8.0000 - size: 39.0000 - loss: 1.0408 - categorical_accuracy: 0.6018 - val_loss: 7.1771 - val_categorical_accuracy: 0.1800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f312e896bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVh5rIRCNVr7"
      },
      "source": [
        "### Observation\n",
        "\n",
        "**As we see from the above experiments image resolution and number of frames in sequence have more impact on training time than batch_size.**\n",
        "\n",
        "So experimentations are carried with batch size fixed around 15-40 and changing the resolution and number of image per sequence based on the device memory constraints . Models are designed such that their memory foot print is less than 50 MB which corresponds to 4.3 million parameters assuming the datatype size of parameters to be 12 bytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKbxe-Szy15j"
      },
      "source": [
        "## Model 1 - Base Model - No Data Augmentation Batch Size 40 and Epoch 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LVQM4NsNVr7"
      },
      "source": [
        "class ModelConv3D1(ModelBuilder):\r\n",
        "    \r\n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\r\n",
        "\r\n",
        "        model = Sequential()\r\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\r\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Flatten())\r\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(dropout))\r\n",
        "\r\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(dropout))\r\n",
        "\r\n",
        "\r\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\r\n",
        "\r\n",
        "        optimiser = optimizers.Adam()\r\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\r\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-89dV5W8WAw3",
        "outputId": "6fb43622-3b41-434d-9ecb-1a7520f4c960"
      },
      "source": [
        "conv_3d1.clear_session(conv_3d1_model)\r\n",
        "Conv3D1=ModelConv3D1()\r\n",
        "Conv3D1.initialize_src_path(main_folder)\r\n",
        "Conv3D1.initialize_image_properties(image_height=160,image_width=160)\r\n",
        "Conv3D1.initialize_hyperparams(frames_to_sample=20,batch_size=40,num_epochs=15)\r\n",
        "Conv3D1_model=Conv3D1.define_model()\r\n",
        "Conv3D1_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 20, 160, 160, 16)  1312      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 20, 160, 160, 16)  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 20, 160, 160, 16)  64        \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 10, 80, 80, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 10, 80, 80, 32)    13856     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10, 80, 80, 32)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 10, 80, 80, 32)    128       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 5, 40, 40, 32)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 5, 40, 40, 64)     55360     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 5, 40, 40, 64)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 5, 40, 40, 64)     256       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 2, 20, 20, 64)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 2, 20, 20, 128)    221312    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2, 20, 20, 128)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 20, 20, 128)    512       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 1, 10, 10, 128)    0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                819264    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 1,117,061\n",
            "Trainable params: 1,116,325\n",
            "Non-trainable params: 736\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j884vjoWQD0",
        "outputId": "a4f6ae20-0fb1-43b6-ad1b-8b17a6c16a5c"
      },
      "source": [
        "print(\"Total Params:\", Conv3D1_model.count_params())\r\n",
        "accuracy_check_model_1 = Conv3D1.train_model(Conv3D1_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 1117061\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 1.4970 - categorical_accuracy: 0.4284\n",
            "Epoch 00001: saving model to model_init_2021-03-1618_59_46.959255/model-00001-1.49695-0.42836-2.00776-0.16000.h5\n",
            "48\n",
            "17/17 [==============================] - 230s 13s/step - batch: 8.0000 - size: 39.0000 - loss: 1.4970 - categorical_accuracy: 0.4284 - val_loss: 2.0078 - val_categorical_accuracy: 0.1600\n",
            "Epoch 2/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.9806 - categorical_accuracy: 0.6259\n",
            "Epoch 00002: saving model to model_init_2021-03-1618_59_46.959255/model-00002-0.98061-0.62594-2.63525-0.27000.h5\n",
            "0\n",
            "17/17 [==============================] - 197s 12s/step - batch: 8.0000 - size: 39.0000 - loss: 0.9806 - categorical_accuracy: 0.6259 - val_loss: 2.6353 - val_categorical_accuracy: 0.2700\n",
            "Epoch 3/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.7097 - categorical_accuracy: 0.7511\n",
            "Epoch 00003: saving model to model_init_2021-03-1618_59_46.959255/model-00003-0.70967-0.75113-3.18782-0.22000.h5\n",
            "0\n",
            "17/17 [==============================] - 193s 12s/step - batch: 8.0000 - size: 39.0000 - loss: 0.7097 - categorical_accuracy: 0.7511 - val_loss: 3.1878 - val_categorical_accuracy: 0.2200\n",
            "Epoch 4/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.4927 - categorical_accuracy: 0.8326\n",
            "Epoch 00004: saving model to model_init_2021-03-1618_59_46.959255/model-00004-0.49273-0.83258-3.98157-0.21000.h5\n",
            "0\n",
            "17/17 [==============================] - 194s 12s/step - batch: 8.0000 - size: 39.0000 - loss: 0.4927 - categorical_accuracy: 0.8326 - val_loss: 3.9816 - val_categorical_accuracy: 0.2100\n",
            "Epoch 5/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.3575 - categorical_accuracy: 0.8839\n",
            "Epoch 00005: saving model to model_init_2021-03-1618_59_46.959255/model-00005-0.35747-0.88386-4.74079-0.17000.h5\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "0\n",
            "17/17 [==============================] - 191s 12s/step - batch: 8.0000 - size: 39.0000 - loss: 0.3575 - categorical_accuracy: 0.8839 - val_loss: 4.7408 - val_categorical_accuracy: 0.1700\n",
            "Epoch 6/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.2912 - categorical_accuracy: 0.9080\n",
            "Epoch 00006: saving model to model_init_2021-03-1618_59_46.959255/model-00006-0.29120-0.90799-4.57409-0.25000.h5\n",
            "0\n",
            "17/17 [==============================] - 199s 12s/step - batch: 8.0000 - size: 39.0000 - loss: 0.2912 - categorical_accuracy: 0.9080 - val_loss: 4.5741 - val_categorical_accuracy: 0.2500\n",
            "Epoch 7/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.2131 - categorical_accuracy: 0.9367\n",
            "Epoch 00007: saving model to model_init_2021-03-1618_59_46.959255/model-00007-0.21314-0.93665-5.18399-0.21000.h5\n",
            "0\n",
            "17/17 [==============================] - 191s 12s/step - batch: 8.0000 - size: 39.0000 - loss: 0.2131 - categorical_accuracy: 0.9367 - val_loss: 5.1840 - val_categorical_accuracy: 0.2100\n",
            "Epoch 8/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.1969 - categorical_accuracy: 0.9502\n",
            "Epoch 00008: saving model to model_init_2021-03-1618_59_46.959255/model-00008-0.19689-0.95023-5.83516-0.21000.h5\n",
            "0\n",
            "17/17 [==============================] - 197s 12s/step - batch: 8.0000 - size: 39.0000 - loss: 0.1969 - categorical_accuracy: 0.9502 - val_loss: 5.8352 - val_categorical_accuracy: 0.2100\n",
            "Epoch 9/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.1664 - categorical_accuracy: 0.9713\n",
            "Epoch 00009: saving model to model_init_2021-03-1618_59_46.959255/model-00009-0.16636-0.97134-5.79989-0.21000.h5\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "0\n",
            "17/17 [==============================] - 197s 12s/step - batch: 8.0000 - size: 39.0000 - loss: 0.1664 - categorical_accuracy: 0.9713 - val_loss: 5.7999 - val_categorical_accuracy: 0.2100\n",
            "Epoch 10/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.1693 - categorical_accuracy: 0.9608\n",
            "Epoch 00010: saving model to model_init_2021-03-1618_59_46.959255/model-00010-0.16931-0.96078-6.57688-0.21000.h5\n",
            "0\n",
            "17/17 [==============================] - 192s 12s/step - batch: 8.0000 - size: 39.0000 - loss: 0.1693 - categorical_accuracy: 0.9608 - val_loss: 6.5769 - val_categorical_accuracy: 0.2100\n",
            "Epoch 11/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.1478 - categorical_accuracy: 0.9759\n",
            "Epoch 00011: saving model to model_init_2021-03-1618_59_46.959255/model-00011-0.14779-0.97587-6.85915-0.19000.h5\n",
            "0\n",
            "17/17 [==============================] - 195s 12s/step - batch: 8.0000 - size: 39.0000 - loss: 0.1478 - categorical_accuracy: 0.9759 - val_loss: 6.8591 - val_categorical_accuracy: 0.1900\n",
            "Epoch 12/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.1513 - categorical_accuracy: 0.9759\n",
            "Epoch 00012: saving model to model_init_2021-03-1618_59_46.959255/model-00012-0.15131-0.97587-6.55005-0.24000.h5\n",
            "0\n",
            "17/17 [==============================] - 197s 12s/step - batch: 8.0000 - size: 39.0000 - loss: 0.1513 - categorical_accuracy: 0.9759 - val_loss: 6.5501 - val_categorical_accuracy: 0.2400\n",
            "Epoch 13/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.1480 - categorical_accuracy: 0.9729\n",
            "Epoch 00013: saving model to model_init_2021-03-1618_59_46.959255/model-00013-0.14797-0.97285-6.76848-0.21000.h5\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "0\n",
            "17/17 [==============================] - 191s 12s/step - batch: 8.0000 - size: 39.0000 - loss: 0.1480 - categorical_accuracy: 0.9729 - val_loss: 6.7685 - val_categorical_accuracy: 0.2100\n",
            "Epoch 14/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.1366 - categorical_accuracy: 0.9774\n",
            "Epoch 00014: saving model to model_init_2021-03-1618_59_46.959255/model-00014-0.13664-0.97738-6.79737-0.23000.h5\n",
            "0\n",
            "17/17 [==============================] - 196s 12s/step - batch: 8.0000 - size: 39.0000 - loss: 0.1366 - categorical_accuracy: 0.9774 - val_loss: 6.7974 - val_categorical_accuracy: 0.2300\n",
            "Epoch 15/15\n",
            "17/17 [==============================] - ETA: 0s - batch: 8.0000 - size: 39.0000 - loss: 0.1299 - categorical_accuracy: 0.9819\n",
            "Epoch 00015: saving model to model_init_2021-03-1618_59_46.959255/model-00015-0.12993-0.98190-6.74204-0.19000.h5\n",
            "0\n",
            "17/17 [==============================] - 191s 12s/step - batch: 8.0000 - size: 39.0000 - loss: 0.1299 - categorical_accuracy: 0.9819 - val_loss: 6.7420 - val_categorical_accuracy: 0.1900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "r00TPGbNXXhX",
        "outputId": "10439c28-78d0-42fd-f05e-51f6634c59e8"
      },
      "source": [
        "plot(accuracy_check_model_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtxwayy_14Hn"
      },
      "source": [
        "#### Model is clearly overfitting. So we need to do data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJk2twS_2lRx"
      },
      "source": [
        "## Model 2 - Augment Data , (3,3,3) filter & 160x160 image resolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQxHzlc92oOq",
        "outputId": "a080ccd3-fe5f-44e2-a9ec-2e7f45b03655"
      },
      "source": [
        "Conv3D1.clear_session(Conv3D1_model)\r\n",
        "Conv3D2=ModelConv3D1()\r\n",
        "Conv3D2.initialize_src_path(main_folder)\r\n",
        "Conv3D2.initialize_image_properties(image_height=160,image_width=160)\r\n",
        "Conv3D2.initialize_hyperparams(frames_to_sample=20,batch_size=20,num_epochs=25)\r\n",
        "Conv3D2_model=Conv3D2.define_model(dense_neurons=256,dropout=0.5)\r\n",
        "Conv3D2_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 20, 160, 160, 16)  1312      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 20, 160, 160, 16)  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 20, 160, 160, 16)  64        \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 10, 80, 80, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 10, 80, 80, 32)    13856     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10, 80, 80, 32)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 10, 80, 80, 32)    128       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 5, 40, 40, 32)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 5, 40, 40, 64)     55360     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 5, 40, 40, 64)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 5, 40, 40, 64)     256       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 2, 20, 20, 64)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 2, 20, 20, 128)    221312    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2, 20, 20, 128)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 20, 20, 128)    512       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 1, 10, 10, 128)    0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               3277056   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 3,638,981\n",
            "Trainable params: 3,637,477\n",
            "Non-trainable params: 1,504\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCx8waqu3PY9",
        "outputId": "c595b69e-bfeb-455d-c961-f474d21e9bf9"
      },
      "source": [
        "print(\"Total Params:\", Conv3D2_model.count_params())\r\n",
        "accuracy_check_model_2=Conv3D2.train_model(Conv3D2_model,augment_data=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 3638981\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 1.9191 - categorical_accuracy: 0.4103\n",
            "Epoch 00001: saving model to model_init_2021-03-1619_49_03.931325/model-00001-1.91905-0.41026-1.75285-0.32000.h5\n",
            "48\n",
            "34/34 [==============================] - 385s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 1.9191 - categorical_accuracy: 0.4103 - val_loss: 1.7529 - val_categorical_accuracy: 0.3200\n",
            "Epoch 2/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 1.3964 - categorical_accuracy: 0.5400\n",
            "Epoch 00002: saving model to model_init_2021-03-1619_49_03.931325/model-00002-1.39645-0.53997-2.33815-0.34000.h5\n",
            "0\n",
            "34/34 [==============================] - 355s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 1.3964 - categorical_accuracy: 0.5400 - val_loss: 2.3381 - val_categorical_accuracy: 0.3400\n",
            "Epoch 3/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 1.1994 - categorical_accuracy: 0.5618\n",
            "Epoch 00003: saving model to model_init_2021-03-1619_49_03.931325/model-00003-1.19944-0.56184-5.52935-0.26000.h5\n",
            "0\n",
            "34/34 [==============================] - 354s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 1.1994 - categorical_accuracy: 0.5618 - val_loss: 5.5294 - val_categorical_accuracy: 0.2600\n",
            "Epoch 4/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 1.1600 - categorical_accuracy: 0.5958\n",
            "Epoch 00004: saving model to model_init_2021-03-1619_49_03.931325/model-00004-1.16000-0.59578-6.63132-0.25000.h5\n",
            "0\n",
            "34/34 [==============================] - 356s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 1.1600 - categorical_accuracy: 0.5958 - val_loss: 6.6313 - val_categorical_accuracy: 0.2500\n",
            "Epoch 5/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 1.1125 - categorical_accuracy: 0.6056\n",
            "Epoch 00005: saving model to model_init_2021-03-1619_49_03.931325/model-00005-1.11251-0.60558-2.88685-0.27000.h5\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "0\n",
            "34/34 [==============================] - 358s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 1.1125 - categorical_accuracy: 0.6056 - val_loss: 2.8868 - val_categorical_accuracy: 0.2700\n",
            "Epoch 6/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.9109 - categorical_accuracy: 0.6795\n",
            "Epoch 00006: saving model to model_init_2021-03-1619_49_03.931325/model-00006-0.91093-0.67949-3.97602-0.27000.h5\n",
            "0\n",
            "34/34 [==============================] - 360s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.9109 - categorical_accuracy: 0.6795 - val_loss: 3.9760 - val_categorical_accuracy: 0.2700\n",
            "Epoch 7/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.8265 - categorical_accuracy: 0.7074\n",
            "Epoch 00007: saving model to model_init_2021-03-1619_49_03.931325/model-00007-0.82653-0.70739-3.96932-0.29000.h5\n",
            "0\n",
            "34/34 [==============================] - 364s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.8265 - categorical_accuracy: 0.7074 - val_loss: 3.9693 - val_categorical_accuracy: 0.2900\n",
            "Epoch 8/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.7744 - categorical_accuracy: 0.7368\n",
            "Epoch 00008: saving model to model_init_2021-03-1619_49_03.931325/model-00008-0.77443-0.73680-4.23046-0.29000.h5\n",
            "0\n",
            "34/34 [==============================] - 356s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.7744 - categorical_accuracy: 0.7368 - val_loss: 4.2305 - val_categorical_accuracy: 0.2900\n",
            "Epoch 9/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.7421 - categorical_accuracy: 0.7210\n",
            "Epoch 00009: saving model to model_init_2021-03-1619_49_03.931325/model-00009-0.74206-0.72097-4.33614-0.27000.h5\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "0\n",
            "34/34 [==============================] - 364s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.7421 - categorical_accuracy: 0.7210 - val_loss: 4.3361 - val_categorical_accuracy: 0.2700\n",
            "Epoch 10/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6522 - categorical_accuracy: 0.7496\n",
            "Epoch 00010: saving model to model_init_2021-03-1619_49_03.931325/model-00010-0.65224-0.74962-4.16016-0.28000.h5\n",
            "0\n",
            "34/34 [==============================] - 350s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6522 - categorical_accuracy: 0.7496 - val_loss: 4.1602 - val_categorical_accuracy: 0.2800\n",
            "Epoch 11/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6825 - categorical_accuracy: 0.7459\n",
            "Epoch 00011: saving model to model_init_2021-03-1619_49_03.931325/model-00011-0.68255-0.74585-3.46579-0.28000.h5\n",
            "0\n",
            "34/34 [==============================] - 358s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6825 - categorical_accuracy: 0.7459 - val_loss: 3.4658 - val_categorical_accuracy: 0.2800\n",
            "Epoch 12/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.7273 - categorical_accuracy: 0.7391\n",
            "Epoch 00012: saving model to model_init_2021-03-1619_49_03.931325/model-00012-0.72732-0.73906-3.10514-0.30000.h5\n",
            "0\n",
            "34/34 [==============================] - 349s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.7273 - categorical_accuracy: 0.7391 - val_loss: 3.1051 - val_categorical_accuracy: 0.3000\n",
            "Epoch 13/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6825 - categorical_accuracy: 0.7549\n",
            "Epoch 00013: saving model to model_init_2021-03-1619_49_03.931325/model-00013-0.68254-0.75490-2.46385-0.36000.h5\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "0\n",
            "34/34 [==============================] - 348s 10s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6825 - categorical_accuracy: 0.7549 - val_loss: 2.4638 - val_categorical_accuracy: 0.3600\n",
            "Epoch 14/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6165 - categorical_accuracy: 0.7670\n",
            "Epoch 00014: saving model to model_init_2021-03-1619_49_03.931325/model-00014-0.61647-0.76697-2.09655-0.35000.h5\n",
            "0\n",
            "34/34 [==============================] - 350s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6165 - categorical_accuracy: 0.7670 - val_loss: 2.0965 - val_categorical_accuracy: 0.3500\n",
            "Epoch 15/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.7184 - categorical_accuracy: 0.7519\n",
            "Epoch 00015: saving model to model_init_2021-03-1619_49_03.931325/model-00015-0.71845-0.75189-1.92763-0.38000.h5\n",
            "0\n",
            "34/34 [==============================] - 352s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.7184 - categorical_accuracy: 0.7519 - val_loss: 1.9276 - val_categorical_accuracy: 0.3800\n",
            "Epoch 16/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6131 - categorical_accuracy: 0.7647\n",
            "Epoch 00016: saving model to model_init_2021-03-1619_49_03.931325/model-00016-0.61306-0.76471-1.52612-0.47000.h5\n",
            "0\n",
            "34/34 [==============================] - 352s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6131 - categorical_accuracy: 0.7647 - val_loss: 1.5261 - val_categorical_accuracy: 0.4700\n",
            "Epoch 17/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.7082 - categorical_accuracy: 0.7391\n",
            "Epoch 00017: saving model to model_init_2021-03-1619_49_03.931325/model-00017-0.70823-0.73906-1.37001-0.53000.h5\n",
            "0\n",
            "34/34 [==============================] - 352s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.7082 - categorical_accuracy: 0.7391 - val_loss: 1.3700 - val_categorical_accuracy: 0.5300\n",
            "Epoch 18/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6448 - categorical_accuracy: 0.7602\n",
            "Epoch 00018: saving model to model_init_2021-03-1619_49_03.931325/model-00018-0.64481-0.76018-1.12167-0.63000.h5\n",
            "0\n",
            "34/34 [==============================] - 350s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6448 - categorical_accuracy: 0.7602 - val_loss: 1.1217 - val_categorical_accuracy: 0.6300\n",
            "Epoch 19/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6298 - categorical_accuracy: 0.7609\n",
            "Epoch 00019: saving model to model_init_2021-03-1619_49_03.931325/model-00019-0.62979-0.76094-1.00751-0.66000.h5\n",
            "0\n",
            "34/34 [==============================] - 349s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6298 - categorical_accuracy: 0.7609 - val_loss: 1.0075 - val_categorical_accuracy: 0.6600\n",
            "Epoch 20/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6754 - categorical_accuracy: 0.7534\n",
            "Epoch 00020: saving model to model_init_2021-03-1619_49_03.931325/model-00020-0.67536-0.75339-0.83984-0.68000.h5\n",
            "0\n",
            "34/34 [==============================] - 356s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6754 - categorical_accuracy: 0.7534 - val_loss: 0.8398 - val_categorical_accuracy: 0.6800\n",
            "Epoch 21/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6749 - categorical_accuracy: 0.7541\n",
            "Epoch 00021: saving model to model_init_2021-03-1619_49_03.931325/model-00021-0.67494-0.75415-0.79592-0.70000.h5\n",
            "0\n",
            "34/34 [==============================] - 364s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6749 - categorical_accuracy: 0.7541 - val_loss: 0.7959 - val_categorical_accuracy: 0.7000\n",
            "Epoch 22/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6055 - categorical_accuracy: 0.7647\n",
            "Epoch 00022: saving model to model_init_2021-03-1619_49_03.931325/model-00022-0.60554-0.76471-0.79071-0.72000.h5\n",
            "0\n",
            "34/34 [==============================] - 360s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6055 - categorical_accuracy: 0.7647 - val_loss: 0.7907 - val_categorical_accuracy: 0.7200\n",
            "Epoch 23/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.5822 - categorical_accuracy: 0.7760\n",
            "Epoch 00023: saving model to model_init_2021-03-1619_49_03.931325/model-00023-0.58218-0.77602-0.64308-0.74000.h5\n",
            "0\n",
            "34/34 [==============================] - 360s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.5822 - categorical_accuracy: 0.7760 - val_loss: 0.6431 - val_categorical_accuracy: 0.7400\n",
            "Epoch 24/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6550 - categorical_accuracy: 0.7783\n",
            "Epoch 00024: saving model to model_init_2021-03-1619_49_03.931325/model-00024-0.65496-0.77828-0.63092-0.77000.h5\n",
            "0\n",
            "34/34 [==============================] - 350s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6550 - categorical_accuracy: 0.7783 - val_loss: 0.6309 - val_categorical_accuracy: 0.7700\n",
            "Epoch 25/25\n",
            "34/34 [==============================] - ETA: 0s - batch: 16.5000 - size: 39.0000 - loss: 0.6310 - categorical_accuracy: 0.7519\n",
            "Epoch 00025: saving model to model_init_2021-03-1619_49_03.931325/model-00025-0.63104-0.75189-0.67765-0.76000.h5\n",
            "0\n",
            "34/34 [==============================] - 349s 11s/step - batch: 16.5000 - size: 39.0000 - loss: 0.6310 - categorical_accuracy: 0.7519 - val_loss: 0.6776 - val_categorical_accuracy: 0.7600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "PXZ8sThy3XSr",
        "outputId": "dde790fd-2966-4e90-90c3-d8e9fbfb2dc6"
      },
      "source": [
        "plot(accuracy_check_model_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldsJg52PTDPq"
      },
      "source": [
        "Model is not overfitting and we get a best validation accuracy of ~80% and training accuracy of ~82%. Next we will try to reduce the filter size and image resolution and see if get better results. Moreover since we see minor oscillations in loss, let's try lowering the learning rate to 0.0002"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDO0BmuThfN_"
      },
      "source": [
        "Conv3D2.clear_session(Conv3D2_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qrMlLsVTSA7"
      },
      "source": [
        "## Model 3 - Reduce filter size to (2,2,2) and image res to 120 x 120"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkPpJFg3TRLh"
      },
      "source": [
        "class ModelConv3D3(ModelBuilder):\r\n",
        "    \r\n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\r\n",
        "\r\n",
        "        model = Sequential()\r\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\r\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Flatten())\r\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(dropout))\r\n",
        "\r\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(dropout))\r\n",
        "\r\n",
        "\r\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\r\n",
        "\r\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\r\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\r\n",
        "        return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk9L9pt7UBB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b8d66fc-ba3f-44fc-d74c-398f0ae00318"
      },
      "source": [
        "\r\n",
        "Conv3D3=ModelConv3D3()\r\n",
        "Conv3D3.initialize_src_path(main_folder)\r\n",
        "Conv3D3.initialize_image_properties(image_height=120,image_width=120)\r\n",
        "Conv3D3.initialize_hyperparams(frames_to_sample=16,batch_size=30,num_epochs=30)\r\n",
        "Conv3D3_model=Conv3D3.define_model(filtersize=(2,2,2),dense_neurons=256,dropout=0.5)\r\n",
        "Conv3D3_model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 16, 120, 120, 16)  400       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 16, 120, 120, 16)  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 16, 120, 120, 16)  64        \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 8, 60, 60, 16)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 8, 60, 60, 32)     4128      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 8, 60, 60, 32)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 60, 60, 32)     128       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 4, 30, 30, 32)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 4, 30, 30, 64)     16448     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 4, 30, 30, 64)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 4, 30, 30, 64)     256       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 2, 15, 15, 64)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 2, 15, 15, 128)    65664     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2, 15, 15, 128)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 15, 15, 128)    512       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 1, 7, 7, 128)      0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               1605888   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 1,762,613\n",
            "Trainable params: 1,761,109\n",
            "Non-trainable params: 1,504\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW17sf6iUcQh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2571fb51-58af-4e89-f260-4d1a1cfb7636"
      },
      "source": [
        "##tf.compat.v1.enable_eager_execution()\r\n",
        "print(tf.executing_eagerly())\r\n",
        "print(\"Total Params:\", Conv3D3_model.count_params())\r\n",
        "accuracy_check_model_3=Conv3D3.train_model(Conv3D3_model,augment_data=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Total Params: 1762613\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/30\n",
            "23/23 [==============================] - 245s 10s/step - loss: 2.3196 - categorical_accuracy: 0.2668 - val_loss: 1.9330 - val_categorical_accuracy: 0.2100\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-03-1700_12_08.462801/model-00001-2.16032-0.31373-1.93303-0.21000.h5\n",
            "12\n",
            "Epoch 2/30\n",
            "23/23 [==============================] - 213s 10s/step - loss: 1.6101 - categorical_accuracy: 0.4821 - val_loss: 3.0607 - val_categorical_accuracy: 0.1500\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-03-1700_12_08.462801/model-00002-1.54150-0.49849-3.06068-0.15000.h5\n",
            "0\n",
            "Epoch 3/30\n",
            "23/23 [==============================] - 212s 10s/step - loss: 1.3712 - categorical_accuracy: 0.5277 - val_loss: 3.9951 - val_categorical_accuracy: 0.2000\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-03-1700_12_08.462801/model-00003-1.32599-0.54676-3.99511-0.20000.h5\n",
            "0\n",
            "Epoch 4/30\n",
            "23/23 [==============================] - 201s 9s/step - loss: 1.2176 - categorical_accuracy: 0.5841 - val_loss: 5.1031 - val_categorical_accuracy: 0.1700\n",
            "\n",
            "Epoch 00004: saving model to model_init_2021-03-1700_12_08.462801/model-00004-1.14791-0.59729-5.10305-0.17000.h5\n",
            "0\n",
            "Epoch 5/30\n",
            "23/23 [==============================] - 201s 9s/step - loss: 1.0345 - categorical_accuracy: 0.6399 - val_loss: 5.6838 - val_categorical_accuracy: 0.1600\n",
            "\n",
            "Epoch 00005: saving model to model_init_2021-03-1700_12_08.462801/model-00005-1.04497-0.64404-5.68378-0.16000.h5\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n",
            "0\n",
            "Epoch 6/30\n",
            "23/23 [==============================] - 212s 10s/step - loss: 0.9652 - categorical_accuracy: 0.6567 - val_loss: 5.7626 - val_categorical_accuracy: 0.1500\n",
            "\n",
            "Epoch 00006: saving model to model_init_2021-03-1700_12_08.462801/model-00006-0.95898-0.65460-5.76255-0.15000.h5\n",
            "0\n",
            "Epoch 7/30\n",
            "23/23 [==============================] - 210s 10s/step - loss: 0.9882 - categorical_accuracy: 0.6322 - val_loss: 6.3369 - val_categorical_accuracy: 0.1900\n",
            "\n",
            "Epoch 00007: saving model to model_init_2021-03-1700_12_08.462801/model-00007-0.99102-0.63801-6.33686-0.19000.h5\n",
            "0\n",
            "Epoch 8/30\n",
            "11/23 [=============>................] - ETA: 1:40 - loss: 0.8281 - categorical_accuracy: 0.6924"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HghaRZtGQB9"
      },
      "source": [
        "plot(accuracy_check_model_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ8jW39zjSXp"
      },
      "source": [
        "Conv3D3.clear_session(Conv3D3_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW5VAmu9ihlH"
      },
      "source": [
        "## Model 4 - Adding more layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cyJpLxiitoB"
      },
      "source": [
        "class ModelConv3D4(ModelBuilder):\r\n",
        "    \r\n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\r\n",
        "\r\n",
        "        model = Sequential()\r\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\r\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        \r\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\r\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        \r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        \r\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        \r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        \r\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        \r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        \r\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        \r\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "        \r\n",
        "\r\n",
        "        model.add(Flatten())\r\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(dropout))\r\n",
        "\r\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(dropout))\r\n",
        "\r\n",
        "\r\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\r\n",
        "\r\n",
        "        optimiser = optimizers.Adam()\r\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\r\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmOxJwmei5-S"
      },
      "source": [
        "Conv3D4=ModelConv3D4()\r\n",
        "Conv3D4.initialize_src_path(main_folder)\r\n",
        "Conv3D4.initialize_image_properties(image_height=120,image_width=120)\r\n",
        "Conv3D4.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=30)\r\n",
        "Conv3D4_model=Conv3D4.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.5)\r\n",
        "Conv3D4_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoR4sAUBkGDJ"
      },
      "source": [
        "print(\"Total Params:\", Conv3D4_model.count_params())\r\n",
        "accuracy_check_model_4=Conv3D4.train_model(Conv3D4_model,augment_data=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8lzWQankJXv"
      },
      "source": [
        "plot(accuracy_check_model_4)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}